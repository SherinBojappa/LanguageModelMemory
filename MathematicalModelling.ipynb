{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bafdac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d952923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_json(\"test_final.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45010d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_synthetic_test = pd.read_json('synthetic_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b31e5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"lstm_pred\"] = torch.load('lstm_pred.pt')\n",
    "df_test[\"lstm_pred_label\"] = torch.load('lstm_pred_label.pt')\n",
    "df_test[\"bert_pred\"] = torch.load('bert_pred.pt')\n",
    "df_test[\"bert_pred_label\"] = torch.load('bert_pred_label.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e81ddd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_synthetic_test[\"lstm_pred\"] = torch.load('syn_lstm_pred.pt')\n",
    "df_synthetic_test[\"lstm_pred_label\"] = torch.load('syn_lstm_pred_label.pt')\n",
    "df_synthetic_test[\"cnn_pred\"] = torch.load('syn_cnn_pred.pt')\n",
    "df_synthetic_test[\"cnn_pred_label\"] = torch.load('syn_cnn_pred_label.pt')\n",
    "df_synthetic_test[\"tansf_pred\"] = torch.load('new_trans_pred.pt')\n",
    "df_synthetic_test[\"transf_pred_label\"] = torch.load('new_trans_pred_label.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c4612ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"cnn_pred\"] = torch.load('cnn_pred.pt')\n",
    "df_test[\"cnn_pred_label\"] = torch.load('cnn_pred_label.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be9f2dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a82825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/data/sherin/checkpoint_lm/chkpt_lm_bert_wdcy_steplr_recall_best.pt.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20832e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MemNetwork, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(768, 768)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "\n",
    "        x_input = self.linear(x)\n",
    "        op = torch.sum(x_input*y, dim=1)\n",
    "        return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4f0c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this when the model state is saved\n",
    "model = MemNetwork().to(device)\n",
    "PATH = checkpoint_path\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "val_acc_bert = checkpoint['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8aa57dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.610660615917686"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fabc4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(400, 400)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "\n",
    "        x_input = self.linear(x)\n",
    "        op = torch.sum(x_input*y, dim=1)\n",
    "        return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0caa6f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_lstm = '/data/sherin/checkpoint_lm/chkpt_lm_lstm_wdcy_steplr_recall_best.pt.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b01fa3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this when the model state is saved\n",
    "model_lstm = NeuralNetwork().to(device)\n",
    "PATH = checkpoint_path_lstm\n",
    "checkpoint_lstm = torch.load(PATH)\n",
    "model_lstm.load_state_dict(checkpoint_lstm['model_state_dict'])\n",
    "epoch = checkpoint_lstm['epoch']\n",
    "loss = checkpoint_lstm['loss']\n",
    "val_acc_lstm = checkpoint_lstm['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff3c4f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6045335981395695"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e569d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_cnn = 0.586"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac5b9ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_synth_lstm = 0.8162241887905605\n",
    "val_acc_synth_cnn = 0.6882743362831858"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89a6e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_synth_transf = 0.7835763636625038"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1535f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computation of optimal tau from Repeat Before Forgetting paper \n",
    "# https://github.com/amirieb/RbF/blob/31f2608a3939a6a15d49a33c113065e1a4f73b65/rbf_keras/engine/training.py#L1268\n",
    "\n",
    "def compute_optimal_tau(kern, avg_test_acc, y_true, y_pred, dist_test,\n",
    "                        sequence_length_val, x):\n",
    "\n",
    "\n",
    "    #test_accs = np.array(y_true.ravel()) & np.array(y_pred.ravel())\n",
    "    #print(test_accs.shape)\n",
    "    #test_accs = [0.1 if acc < 1. else 0.9 for acc in\n",
    "    #             test_accs.squeeze().tolist()]\n",
    "    # test accs now are continuous non-zero values\n",
    "\n",
    "    test_accs = np.array(y_pred.ravel())\n",
    "    test_accs = [0.001 if test_acc == 0 else test_acc for test_acc in test_accs]\n",
    "\n",
    "\n",
    "    if kern == 'Gaussian':\n",
    "        # throughout training - take average error\n",
    "        # earlyon maybe a different model is better and maybe at the end a diff\n",
    "        # model is good - good to capture\n",
    "        # do this on the validation data\n",
    "\n",
    "        # epochs1 - k use validation acc as strength of model\n",
    "        # at teh end use test acc as strength of model\n",
    "        # s and d normalize - s - 1 - 100  -> 0.01 - 1 d - 0.01 - 1\n",
    "        # use validation acc instead of test acc - best validation acc\n",
    "        # best epoch try all functions - both papers on val data\n",
    "        # then do this for every epoch - val data\n",
    "        # dont use test data to tune hyperparams\n",
    "        # gaussian\n",
    "        \n",
    "        num = -1.0 * np.sum([np.log(a) for a in test_accs])\n",
    "        den = np.sum(np.power(x, 2))\n",
    "\n",
    "    if kern == \"Laplacian\":\n",
    "        num = -1.0 * np.sum([np.log(a) for a in test_accs])\n",
    "        den = np.sum(x)\n",
    "\n",
    "    if kern == \"Linear\":\n",
    "        num = np.sum([(1. - a) for a in test_accs])\n",
    "        den = np.sum(x)\n",
    "\n",
    "    if kern == \"Cosine\":\n",
    "        num = np.sum([np.arccos(1. * a - 1.) for a in test_accs])\n",
    "        den = np.pi * np.sum(x)\n",
    "\n",
    "    if kern == \"Quadratic\":\n",
    "        num = np.sum([(1. - a) for a in test_accs])\n",
    "        den = np.sum(np.power(x, 2))\n",
    "\n",
    "    if kern == \"Secant\":\n",
    "        num = np.sum([np.log(1. / a + np.sqrt(1. / a - 1.)) for a in test_accs])\n",
    "        den = np.sum(x)\n",
    "        \n",
    "\n",
    "    tau = num * 1.0 / den\n",
    "    return tau, test_accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7c4053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_l2_loss(tau, kern, test_accs, x):\n",
    "    test_accs = np.array(test_accs)\n",
    "    if kern == 'Gaussian':\n",
    "        print(\"computing l2 loss\")\n",
    "        #f_gauss = np.exp(-1 * tau * np.sum(np.power(x, 2)))\n",
    "        f_gauss = np.array([np.exp(-1 * tau * np.power(x_i, 2))for x_i in x])\n",
    "        # test_acc b/w 0 and 1\n",
    "        f_gauss_loss = np.mean(np.power((f_gauss - test_accs), 2))\n",
    "        return f_gauss_loss\n",
    "\n",
    "    if kern == \"Laplacian\":\n",
    "        #f_lap = np.exp(-1 * tau * np.sum(x))\n",
    "        f_lap = np.array([np.exp(-1 * tau * x_i) for x_i in x])\n",
    "        # test_acc b/w 0 and 1\n",
    "        f_lap_loss = np.mean(np.power((f_lap - test_accs), 2))\n",
    "        return f_lap_loss\n",
    "\n",
    "    if kern == \"Linear\":\n",
    "        #f_lin = (1 - (1 * tau * np.sum(x)))\n",
    "        f_lin = np.array([(1 - (tau*x_i)) for x_i in x])\n",
    "        #f_lin = np.sum(1 - (tau * x))\n",
    "        f_lin_loss = np.mean(np.power((f_lin - test_accs), 2))\n",
    "        return f_lin_loss\n",
    "\n",
    "    if kern == \"Cosine\":\n",
    "        #f_cos = 1 / 2 * np.cos(tau * np.sum(x) * np.pi)\n",
    "        f_cos = np.array([((0.5 * np.cos(tau * x_i * np.pi)) + 0.5) for x_i in x])\n",
    "        f_cos_loss = np.mean(np.power((f_cos - test_accs), 2))\n",
    "        return f_cos_loss\n",
    "\n",
    "    if kern == \"Quadratic\":\n",
    "        f_qua = np.array([(1 - (tau * np.power(x, 2))) for x_i in x])\n",
    "        f_qua_loss = np.mean(np.power((f_qua - test_accs), 2))\n",
    "        return f_qua_loss\n",
    "\n",
    "    if kern == \"Secant\":\n",
    "        #f_sec = 2 * 1.0 / (np.exp(-1 * tau * np.sum(np.power(x, 2))) + np.exp(\n",
    "        #    1 * tau * np.sum(np.power(x, 2))))\n",
    "        f_sec = np.array([(2*1.0 /(np.exp(-1 * tau * np.power(x_i, 2)) + np.exp(1 * tau * np.power(x, 2))) )for x_i in x])\n",
    "        f_sec_loss = np.mean(np.power((f_sec - test_accs), 2))\n",
    "        return f_sec_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e8803ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_forgetting_functions(forgetting_function, avg_test_acc,\n",
    "                                      dist_test, sequence_length_val, test_accs, val_acc):\n",
    "\n",
    "    # difficulty = seq len; time elapsed since last review = dist; strength =\n",
    "    # average accuracy.\n",
    "    # exp(-seq_len*intervening_tokens/avg_test_acc)\n",
    "\n",
    "    if forgetting_function == 'diff_dist_strength':\n",
    "        x = [((s * d * 1.0) / ((val_acc+np.finfo(float).eps) * 100 * 100)) for s, d in\n",
    "             zip(sequence_length_val, dist_test)]\n",
    "        x = np.array(x)\n",
    "        f_diff_dist_strength = np.exp(-x)\n",
    "        f_diff_dist_strength_loss = np.mean(np.power\n",
    "                                            ((f_diff_dist_strength - test_accs), 2))\n",
    "        return f_diff_dist_strength_loss\n",
    "\n",
    "    # exp(-seq_len*intervening_tokens)\n",
    "    elif forgetting_function == 'diff_dist':\n",
    "        x = [((s * d * 1.0) / (100 * 100)) for s, d in\n",
    "             zip(sequence_length_val, dist_test)]\n",
    "        x = np.array(x)\n",
    "        f_diff_dist = np.exp(-x)\n",
    "        f_diff_dist_loss = np.mean(np.power\n",
    "                                   ((f_diff_dist - test_accs), 2))\n",
    "        return f_diff_dist_loss\n",
    "\n",
    "    # exp(-seq_len/avg_test_acc)\n",
    "    elif forgetting_function == 'diff_strength':\n",
    "        x = [((s * 1.0) / ((val_acc+np.finfo(float).eps) * 100 * 100)) for s, d in\n",
    "             zip(sequence_length_val, dist_test)]\n",
    "        x = np.array(x)\n",
    "        f_diff_strength = np.exp(-x)\n",
    "        f_diff_strength_loss = np.mean(np.power\n",
    "                                       ((f_diff_strength - test_accs), 2))\n",
    "        return f_diff_strength_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3146a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_matching(y_true, y_pred, dist_test, sequence_length_val,\n",
    "                    y_pred_binary_pos_samples, x, val_acc):\n",
    "    kernels = ['Gaussian', 'Laplacian', 'Linear', 'Cosine', 'Quadratic',\n",
    "               'Secant']\n",
    "    avg_test_acc = balanced_accuracy_score(y_true, y_pred_binary_pos_samples)\n",
    "    print(\"computing optimal tau\")\n",
    "    kern_loss = []\n",
    "    tau_kernels = []\n",
    "    exp_forgetting_function_loss = []\n",
    "    # compute x - seq_len*dist\n",
    "\n",
    "    for kern in kernels:\n",
    "        print(\"Kernel type is {}\".format(kern))\n",
    "\n",
    "        tau, test_accs = compute_optimal_tau(kern, avg_test_acc, y_true, y_pred,\n",
    "                                             dist_test, sequence_length_val, x)\n",
    "        tau_kernels.append(tau)\n",
    "        print(\"optimal value of tau is {}\".format(tau))\n",
    "        l2_loss = compute_l2_loss(tau, kern, test_accs, x)\n",
    "        print(\"L2 loss for kernel {} is {}\".format(kern, l2_loss))\n",
    "        kern_loss.append(l2_loss)\n",
    " \n",
    "     # debug only\n",
    "    # compute l2 loss for functions from Reddy et al paper\n",
    "    exp_forgetting_functions = ['diff_dist_strength', 'diff_dist',\n",
    "                                'diff_strength']\n",
    "    \n",
    "    #test_accs = np.array(y_true.ravel()) & np.array(y_pred.ravel())\n",
    "    test_accs = np.array(y_pred.ravel())\n",
    "    for exp_forgetting_function in exp_forgetting_functions:\n",
    "        exp_forgetting_l2_loss = compute_loss_forgetting_functions(\n",
    "            exp_forgetting_function, avg_test_acc, dist_test, sequence_length_val,\n",
    "            test_accs, val_acc)\n",
    "        exp_forgetting_function_loss.append(exp_forgetting_l2_loss)\n",
    "        print(\"L2 loss for forgetting function {} is {}\".format(exp_forgetting_function, exp_forgetting_l2_loss))\n",
    "\n",
    "\n",
    "    # find the least loss\n",
    "    min_index = kern_loss.index(min(kern_loss))\n",
    "    print(\"The best kernel is {}\".format(kernels[min_index]))\n",
    "    print(\"the value of the loss is {}\".format(min(kern_loss)))\n",
    "\n",
    "    min_index_exp_forgetting_function = \\\n",
    "        exp_forgetting_function_loss.index(min(exp_forgetting_function_loss))\n",
    "    print(\"The best forgetting function is {}\".format(exp_forgetting_functions[min_index_exp_forgetting_function]))\n",
    "\n",
    "    print(\"the value of the loss is {}\".format(min(exp_forgetting_function_loss)))\n",
    "\n",
    "    return kernels[min_index], tau_kernels[min_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e72c76a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the positive samples - 16901 samples\n",
    "df_test_pos = df_test[df_test['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "632c25e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intervening_tokens(c, q, l):\n",
    "    try:\n",
    "        int_tok = 512 - c.split(\" \").index(q) - 1\n",
    "    except:\n",
    "        int_tok = -1\n",
    "    \n",
    "    return int_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "baea5400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tf14/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_test_pos[\"int_tok\"] = df_test_pos.apply(lambda x: get_intervening_tokens(x['context'], x['query'], x['context_length']), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7532a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f26054ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the relevant columns and convert them into numpy array to reuse the synthetic code\n",
    "target_val_pos_samples = df_test_pos['label'].to_numpy()\n",
    "\n",
    "bert_y_pred_pos_samples = df_test_pos['bert_pred'].to_numpy()\n",
    "lstm_y_pred_pos_samples = df_test_pos['lstm_pred'].to_numpy()\n",
    "cnn_y_pred_pos_samples = df_test_pos['cnn_pred'].to_numpy()\n",
    "\n",
    "\n",
    "dist_pos_samples = df_test_pos['int_tok'].to_numpy()\n",
    "seq_len_test_pos_samples = df_test_pos['context_length'].to_numpy()\n",
    "\n",
    "bert_y_pred_binary_pos_samples = df_test_pos['bert_pred_label'].to_numpy()\n",
    "lstm_y_pred_binary_pos_samples = df_test_pos['lstm_pred_label'].to_numpy()\n",
    "cnn_y_pred_binary_pos_samples = df_test_pos['cnn_pred_label'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "892a70b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute x\n",
    "# difficulty = seq len; time elapsed since last review = dist; strength =\n",
    "# average accuracy.\n",
    "# normalize s and d by dividing by 100\n",
    "x_bert = [((s * d * 1.0) / ((val_acc_bert+np.finfo(float).eps) * 100 * 100)) for s, d in\n",
    "         zip(seq_len_test_pos_samples, dist_pos_samples)]\n",
    "\n",
    "x_lstm = [((s * d * 1.0) / ((val_acc_lstm+np.finfo(float).eps) * 100 * 100)) for s, d in\n",
    "         zip(seq_len_test_pos_samples, dist_pos_samples)]\n",
    "    \n",
    "x_cnn = [((s * d * 1.0) / ((val_acc_cnn+np.finfo(float).eps) * 100 * 100)) for s, d in\n",
    "         zip(seq_len_test_pos_samples, dist_pos_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76c74d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing optimal tau\n",
      "Kernel type is Gaussian\n",
      "optimal value of tau is 0.03264930054717812\n",
      "computing l2 loss\n",
      "L2 loss for kernel Gaussian is 0.6590702119650492\n",
      "Kernel type is Laplacian\n",
      "optimal value of tau is 0.5395132164006848\n",
      "L2 loss for kernel Laplacian is 0.671934146396757\n",
      "Kernel type is Linear\n",
      "optimal value of tau is 0.022616831608982358\n",
      "L2 loss for kernel Linear is 0.2531979153063546\n",
      "Kernel type is Cosine\n",
      "optimal value of tau is 0.04703716542737344\n",
      "L2 loss for kernel Cosine is 0.4402867721655349\n",
      "Kernel type is Quadratic\n",
      "optimal value of tau is 0.0013686851594719262\n",
      "L2 loss for kernel Quadratic is 0.3224170532340216\n",
      "Kernel type is Secant\n",
      "optimal value of tau is 0.541486383729324\n",
      "L2 loss for kernel Secant is 0.6818845042600029\n",
      "L2 loss for forgetting function diff_dist_strength is 0.6766405352510189\n",
      "L2 loss for forgetting function diff_dist is 0.6738540179824547\n",
      "L2 loss for forgetting function diff_strength is 0.2846763645712736\n",
      "The best kernel is Linear\n",
      "the value of the loss is 0.2531979153063546\n",
      "The best forgetting function is diff_strength\n",
      "the value of the loss is 0.2846763645712736\n"
     ]
    }
   ],
   "source": [
    "# finding the best kernel to match the memory retention test\n",
    "kernel, tau = kernel_matching(target_val_pos_samples, bert_y_pred_pos_samples,\n",
    "                              dist_pos_samples, seq_len_test_pos_samples,\n",
    "                              bert_y_pred_binary_pos_samples, x_bert, val_acc_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18332f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing optimal tau\n",
      "Kernel type is Gaussian\n",
      "optimal value of tau is 0.006909447270277666\n",
      "computing l2 loss\n",
      "L2 loss for kernel Gaussian is 0.20768180854135618\n",
      "Kernel type is Laplacian\n",
      "optimal value of tau is 0.11533230768341526\n",
      "L2 loss for kernel Laplacian is 0.18787674732125534\n",
      "Kernel type is Linear\n",
      "optimal value of tau is 0.040974960119359374\n",
      "L2 loss for kernel Linear is 0.19452047453523882\n",
      "Kernel type is Cosine\n",
      "optimal value of tau is 0.05183361278558985\n",
      "L2 loss for kernel Cosine is 0.21335240180492043\n",
      "Kernel type is Quadratic\n",
      "optimal value of tau is 0.0024547703244054276\n",
      "L2 loss for kernel Quadratic is 0.3773132203972371\n",
      "Kernel type is Secant\n",
      "optimal value of tau is 0.13492258951837094\n",
      "L2 loss for kernel Secant is 0.3171974889785323\n",
      "L2 loss for forgetting function diff_dist_strength is 0.3009614907462594\n",
      "L2 loss for forgetting function diff_dist is 0.2982823852944072\n",
      "L2 loss for forgetting function diff_strength is 0.40519973640850815\n",
      "The best kernel is Laplacian\n",
      "the value of the loss is 0.18787674732125534\n",
      "The best forgetting function is diff_dist\n",
      "the value of the loss is 0.2982823852944072\n"
     ]
    }
   ],
   "source": [
    "# finding the best kernel to match the memory retention test\n",
    "kernel, tau = kernel_matching(target_val_pos_samples, lstm_y_pred_pos_samples,\n",
    "                              dist_pos_samples, seq_len_test_pos_samples,\n",
    "                              lstm_y_pred_binary_pos_samples, x_lstm, val_acc_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b5602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_test['query'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8d3a87dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing optimal tau\n",
      "Kernel type is Gaussian\n",
      "optimal value of tau is 0.024075917725875876\n",
      "computing l2 loss\n",
      "L2 loss for kernel Gaussian is 0.24260048350911195\n",
      "Kernel type is Laplacian\n",
      "optimal value of tau is 0.414584777856588\n",
      "L2 loss for kernel Laplacian is 0.2479561775327922\n",
      "Kernel type is Linear\n",
      "optimal value of tau is 0.04851545321240991\n",
      "L2 loss for kernel Linear is 0.2558018648411966\n",
      "Kernel type is Cosine\n",
      "optimal value of tau is 0.05702814756959793\n",
      "L2 loss for kernel Cosine is 0.23302157758113093\n",
      "Kernel type is Quadratic\n",
      "optimal value of tau is 0.002817407011454751\n",
      "L2 loss for kernel Quadratic is 0.5197170494377559\n",
      "Kernel type is Secant\n",
      "optimal value of tau is 0.42257829558560117\n",
      "L2 loss for kernel Secant is 0.26058524508401376\n",
      "L2 loss for forgetting function diff_dist_strength is 0.256449556657345\n",
      "L2 loss for forgetting function diff_dist is 0.25319223200607516\n",
      "L2 loss for forgetting function diff_strength is 0.6021174682773007\n",
      "The best kernel is Cosine\n",
      "the value of the loss is 0.23302157758113093\n",
      "The best forgetting function is diff_dist\n",
      "the value of the loss is 0.25319223200607516\n"
     ]
    }
   ],
   "source": [
    "# finding the best kernel to match the memory retention test\n",
    "kernel, tau = kernel_matching(target_val_pos_samples, cnn_y_pred_pos_samples,\n",
    "                              dist_pos_samples, seq_len_test_pos_samples,\n",
    "                              cnn_y_pred_binary_pos_samples, x_cnn, val_acc_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba41cd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_sequence_test = np.load('test_context_query.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ef5500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_tok = np.zeros(len(ip_sequence_test))\n",
    "for i in range(len(ip_sequence_test)):\n",
    "    a = np.where(ip_sequence_test[i][:-1] == ip_sequence_test[i][-1])\n",
    "    if a[0].size == 0:\n",
    "        int_tok[i] = -1 \n",
    "        #print(len(a))\n",
    "    else:\n",
    "        int_tok[i] = len(ip_sequence_test[i][:-1]) - a[0][0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8db24195",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_synthetic_test[\"int_tok\"] = int_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec9802fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_synthetic_test_pos = df_synthetic_test[df_synthetic_test['target_val'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b572fc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>seq</th>\n",
       "      <th>rep_token_first_pos</th>\n",
       "      <th>query_token</th>\n",
       "      <th>target_val</th>\n",
       "      <th>lstm_pred</th>\n",
       "      <th>lstm_pred_label</th>\n",
       "      <th>cnn_pred</th>\n",
       "      <th>cnn_pred_label</th>\n",
       "      <th>tansf_pred</th>\n",
       "      <th>transf_pred_label</th>\n",
       "      <th>int_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84812</th>\n",
       "      <td>84812</td>\n",
       "      <td>45</td>\n",
       "      <td>[17 30 76 12 43 65  5 71 89 62 83 88 32 99 68 ...</td>\n",
       "      <td>33</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.335489</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163418</th>\n",
       "      <td>163418</td>\n",
       "      <td>84</td>\n",
       "      <td>[93 12 79 87 90 94 15  0  9 95 11 70 18 23 52 ...</td>\n",
       "      <td>22</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984755</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154870</th>\n",
       "      <td>154870</td>\n",
       "      <td>80</td>\n",
       "      <td>[82 65 51 88 98 66  5 97 32 53 91  6 55 15 29 ...</td>\n",
       "      <td>54</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>9.947405e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974092</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128894</th>\n",
       "      <td>128894</td>\n",
       "      <td>67</td>\n",
       "      <td>[57  9 72 52 31 46 97 37  7 96 44 74 69 81 91 ...</td>\n",
       "      <td>9</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>7.574954e-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.936459</td>\n",
       "      <td>1</td>\n",
       "      <td>0.122071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165684</th>\n",
       "      <td>165684</td>\n",
       "      <td>85</td>\n",
       "      <td>[78 87 80 65 43 39 19 27 74 11 94 62 60 25 73 ...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.695454</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  seq_len                                                seq  \\\n",
       "84812    84812       45  [17 30 76 12 43 65  5 71 89 62 83 88 32 99 68 ...   \n",
       "163418  163418       84  [93 12 79 87 90 94 15  0  9 95 11 70 18 23 52 ...   \n",
       "154870  154870       80  [82 65 51 88 98 66  5 97 32 53 91  6 55 15 29 ...   \n",
       "128894  128894       67  [57  9 72 52 31 46 97 37  7 96 44 74 69 81 91 ...   \n",
       "165684  165684       85  [78 87 80 65 43 39 19 27 74 11 94 62 60 25 73 ...   \n",
       "\n",
       "        rep_token_first_pos  query_token  target_val     lstm_pred  \\\n",
       "84812                    33           98           1  1.000000e+00   \n",
       "163418                   22           85           1  1.000000e+00   \n",
       "154870                   54           20           1  9.947405e-01   \n",
       "128894                    9           96           1  7.574954e-18   \n",
       "165684                    9           11           1  1.000000e+00   \n",
       "\n",
       "        lstm_pred_label  cnn_pred  cnn_pred_label  tansf_pred  \\\n",
       "84812                 1  0.335489               0    0.998704   \n",
       "163418                1  0.984755               1    0.978039   \n",
       "154870                1  0.974092               1    0.998642   \n",
       "128894                0  0.936459               1    0.122071   \n",
       "165684                1  0.695454               1    0.588875   \n",
       "\n",
       "        transf_pred_label  int_tok  \n",
       "84812                 1.0     11.0  \n",
       "163418                1.0     61.0  \n",
       "154870                1.0     25.0  \n",
       "128894                0.0     57.0  \n",
       "165684                1.0     75.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_synthetic_test_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab7ee1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the relevant columns and convert them into numpy array to reuse the synthetic code\n",
    "target_val_pos_samples = df_synthetic_test_pos['target_val'].to_numpy()\n",
    "\n",
    "lstm_y_pred_pos_samples = df_synthetic_test_pos['lstm_pred'].to_numpy()\n",
    "cnn_y_pred_pos_samples = df_synthetic_test_pos['cnn_pred'].to_numpy()\n",
    "tansf_y_pred_pos_samples = df_synthetic_test_pos['tansf_pred'].to_numpy()\n",
    "\n",
    "dist_pos_samples = df_synthetic_test_pos['int_tok'].to_numpy()\n",
    "seq_len_test_pos_samples = df_synthetic_test_pos['seq_len'].to_numpy()\n",
    "\n",
    "lstm_y_pred_binary_pos_samples = df_synthetic_test_pos['lstm_pred_label'].to_numpy()\n",
    "cnn_y_pred_binary_pos_samples = df_synthetic_test_pos['cnn_pred_label'].to_numpy()\n",
    "transf_y_pred_binary_pos_samples = df_synthetic_test_pos['transf_pred_label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d01850e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_acc_synth_lstm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_517662/3705592228.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m x_lstm_synth = [((s * d * 1.0) / ((val_acc_synth_lstm+np.finfo(float).eps) * 100 * 100)) for s, d in\n\u001b[0;32m----> 9\u001b[0;31m          zip(seq_len_test_pos_samples, dist_pos_samples)]\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m x_cnn_synth = [((s * d * 1.0) / ((val_acc_synth_cnn+np.finfo(float).eps) * 100 * 100)) for s, d in\n",
      "\u001b[0;32m/tmp/ipykernel_517662/3705592228.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#         zip(seq_len_test_pos_samples, dist_pos_samples)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m x_lstm_synth = [((s * d * 1.0) / ((val_acc_synth_lstm+np.finfo(float).eps) * 100 * 100)) for s, d in\n\u001b[0m\u001b[1;32m      9\u001b[0m          zip(seq_len_test_pos_samples, dist_pos_samples)]\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_acc_synth_lstm' is not defined"
     ]
    }
   ],
   "source": [
    "# compute x\n",
    "# difficulty = seq len; time elapsed since last review = dist; strength =\n",
    "# average accuracy.\n",
    "# normalize s and d by dividing by 100\n",
    "#x_bert = [((s * d * 1.0) / ((val_acc_bert+np.finfo(float).eps) * 100 * 100)) for s, d in\n",
    "#         zip(seq_len_test_pos_samples, dist_pos_samples)]\n",
    "\n",
    "x_lstm_synth = [((s * d * 1.0) / ((val_acc_synth_lstm+np.finfo(float).eps) * 100 * 100)) for s, d in\n",
    "         zip(seq_len_test_pos_samples, dist_pos_samples)]\n",
    "    \n",
    "x_cnn_synth = [((s * d * 1.0) / ((val_acc_synth_cnn+np.finfo(float).eps) * 100 * 100)) for s, d in\n",
    "         zip(seq_len_test_pos_samples, dist_pos_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e04f9985",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_transf_synth = [((s * d * 1.0) / ((val_acc_synth_transf+np.finfo(float).eps) * 100 * 100)) for s, d in\n",
    "         zip(seq_len_test_pos_samples, dist_pos_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e7a0aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tf14/lib/python3.7/site-packages/sklearn/metrics/classification.py:1745: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing optimal tau\n",
      "Kernel type is Gaussian\n",
      "optimal value of tau is 23.845543254239377\n",
      "computing l2 loss\n",
      "L2 loss for kernel Gaussian is 0.2575309079412811\n",
      "Kernel type is Laplacian\n",
      "optimal value of tau is 11.419156181330422\n",
      "L2 loss for kernel Laplacian is 0.3563615088471858\n",
      "Kernel type is Linear\n",
      "optimal value of tau is 0.9655074939135232\n",
      "L2 loss for kernel Linear is 0.1439239766526381\n",
      "Kernel type is Cosine\n",
      "optimal value of tau is 2.8856885101830296\n",
      "L2 loss for kernel Cosine is 0.2198103798381932\n",
      "Kernel type is Quadratic\n",
      "optimal value of tau is 2.0161779331863743\n",
      "L2 loss for kernel Quadratic is 0.22045687635941513\n",
      "Kernel type is Secant\n",
      "optimal value of tau is 11.589805745770215\n",
      "L2 loss for kernel Secant is 0.32773486344682806\n",
      "L2 loss for forgetting function diff_dist_strength is 0.1337452500329711\n",
      "L2 loss for forgetting function diff_dist is 0.13480035937442192\n",
      "L2 loss for forgetting function diff_strength is 0.18242147923892027\n",
      "The best kernel is Linear\n",
      "the value of the loss is 0.1439239766526381\n",
      "The best forgetting function is diff_dist_strength\n",
      "the value of the loss is 0.1337452500329711\n"
     ]
    }
   ],
   "source": [
    "# finding the best kernel to match the memory retention test\n",
    "kernel, tau = kernel_matching(target_val_pos_samples, lstm_y_pred_pos_samples,\n",
    "                              dist_pos_samples, seq_len_test_pos_samples,\n",
    "                              lstm_y_pred_binary_pos_samples, x_lstm_synth, val_acc_synth_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8708958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing optimal tau\n",
      "Kernel type is Gaussian\n",
      "optimal value of tau is 4.725299249063713\n",
      "computing l2 loss\n",
      "L2 loss for kernel Gaussian is 0.18777452761474392\n",
      "Kernel type is Laplacian\n",
      "optimal value of tau is 2.6835147928518195\n",
      "L2 loss for kernel Laplacian is 0.16341907656093382\n",
      "Kernel type is Linear\n",
      "optimal value of tau is 1.2957197168992913\n",
      "L2 loss for kernel Linear is 0.20218873979145927\n",
      "Kernel type is Cosine\n",
      "optimal value of tau is 2.528415213098354\n",
      "L2 loss for kernel Cosine is 0.19375322844416693\n",
      "Kernel type is Quadratic\n",
      "optimal value of tau is 2.281583623675353\n",
      "L2 loss for kernel Quadratic is 0.44167978694767923\n",
      "Kernel type is Secant\n",
      "optimal value of tau is 3.7186251360364784\n",
      "L2 loss for kernel Secant is 0.3128883297610826\n",
      "L2 loss for forgetting function diff_dist_strength is 0.13595279890471793\n",
      "L2 loss for forgetting function diff_dist is 0.14146703354839776\n",
      "L2 loss for forgetting function diff_strength is 0.1989300329202723\n",
      "The best kernel is Laplacian\n",
      "the value of the loss is 0.16341907656093382\n",
      "The best forgetting function is diff_dist_strength\n",
      "the value of the loss is 0.13595279890471793\n"
     ]
    }
   ],
   "source": [
    "# finding the best kernel to match the memory retention test\n",
    "kernel, tau = kernel_matching(target_val_pos_samples, cnn_y_pred_pos_samples,\n",
    "                              dist_pos_samples, seq_len_test_pos_samples,\n",
    "                              cnn_y_pred_binary_pos_samples, x_cnn_synth, val_acc_synth_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4169b9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing optimal tau\n",
      "Kernel type is Gaussian\n",
      "optimal value of tau is 5.03393164004504\n",
      "computing l2 loss\n",
      "L2 loss for kernel Gaussian is 0.20707940090133176\n",
      "Kernel type is Laplacian\n",
      "optimal value of tau is 2.5110897725647376\n",
      "L2 loss for kernel Laplacian is 0.18869507452724185\n",
      "Kernel type is Linear\n",
      "optimal value of tau is 1.1416449916109557\n",
      "L2 loss for kernel Linear is 0.18402130330445773\n",
      "Kernel type is Cosine\n",
      "optimal value of tau is 2.760149001567948\n",
      "L2 loss for kernel Cosine is 0.22296297873913878\n",
      "Kernel type is Quadratic\n",
      "optimal value of tau is 2.288632970337656\n",
      "L2 loss for kernel Quadratic is 0.33977207070623794\n",
      "Kernel type is Secant\n",
      "optimal value of tau is 3.4954278831778263\n",
      "L2 loss for kernel Secant is 0.27275157273665296\n",
      "L2 loss for forgetting function diff_dist_strength is 0.13626779929915653\n",
      "L2 loss for forgetting function diff_dist is 0.13259756722115076\n",
      "L2 loss for forgetting function diff_strength is 0.15394165537219165\n",
      "The best kernel is Linear\n",
      "the value of the loss is 0.18402130330445773\n",
      "The best forgetting function is diff_dist\n",
      "the value of the loss is 0.13259756722115076\n"
     ]
    }
   ],
   "source": [
    "# finding the best kernel to match the memory retention test\n",
    "kernel, tau = kernel_matching(target_val_pos_samples, tansf_y_pred_pos_samples,\n",
    "                              dist_pos_samples, seq_len_test_pos_samples,\n",
    "                              transf_y_pred_binary_pos_samples, x_transf_synth, val_acc_synth_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017e0f33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
