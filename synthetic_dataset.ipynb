{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f32a61d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd0e2c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29334739",
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_PATH = '/data/sherin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a7ae2718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(INP_PATH + \"memory_retention_raw.csv\",\n",
    "                         usecols=['index', 'seq_len', 'seq',\n",
    "                                  'rep_token_first_pos',\n",
    "                                  'query_token', 'target_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b6368466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                   35\n",
       "seq_len                  1\n",
       "seq                    [4]\n",
       "rep_token_first_pos     -1\n",
       "query_token             10\n",
       "target_val               0\n",
       "Name: 35, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3cab1386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193714,)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for s in ip_sequence:\n",
    "    c = s[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d2cbd385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([19, 19]), array([72, 11]), array([87, 87]), ...,\n",
       "       array([ 0, 30, 97, 44, 66, 69, 83, 21, 31, 34, 87, 28, 77, 22, 98, 86, 25,\n",
       "              20,  3, 12, 50,  6, 71, 24, 91, 36, 43, 26, 90, 59, 72, 27, 64, 65,\n",
       "               1, 14,  2, 40, 85, 92, 18,  9, 13, 88, 78, 93, 73, 51, 79, 58, 42,\n",
       "              33, 60, 16, 47, 52, 74, 19, 82,  7, 37, 35, 10,  5, 41, 67, 84, 29,\n",
       "              80, 45, 23,  4, 99, 94, 38, 89,  8, 49, 63, 76, 39, 70, 17, 54, 95,\n",
       "              32, 81, 11, 61, 46, 57, 55, 56, 75, 53, 62, 68, 96, 15, 48])       ,\n",
       "       array([ 4, 13, 64, 53, 77, 27, 39, 32, 16,  3, 35, 61, 62, 74, 73, 45, 82,\n",
       "              10, 81, 34, 26, 56, 92, 58, 17, 75, 97,  9,  8, 52, 80, 30, 69, 89,\n",
       "               0, 46, 11, 49, 70, 23, 86, 78, 95, 24,  7, 67, 91, 28, 33, 43, 20,\n",
       "              60, 72,  1, 29, 57, 76, 14, 84, 99,  5, 12, 31, 38,  6, 48, 51,  2,\n",
       "              21, 85, 83, 55, 98, 54, 88, 65, 66, 41, 15, 22, 44, 79, 63, 68, 94,\n",
       "              87, 36, 37, 47, 59, 50, 71, 40, 42, 19, 96, 93, 90, 25,  1])       ,\n",
       "       array([21, 47,  4, 78, 25, 56, 72, 92, 86, 83, 98, 68, 38, 59, 26, 50, 96,\n",
       "              82, 41, 74, 91, 60, 16,  0, 71, 88, 39, 99,  9,  6, 45, 57, 67, 12,\n",
       "              89, 46, 65, 61, 32,  5, 48, 52, 40, 80, 93, 90, 58,  7, 14, 81, 70,\n",
       "              76, 27, 19, 66, 22,  3, 20, 44, 97,  8, 13, 63, 79, 29, 54, 53, 36,\n",
       "              75, 51, 94, 84, 31, 42, 87, 95, 15, 77, 28, 34, 11, 37, 85, 49,  2,\n",
       "               1, 55, 17, 73, 23, 33, 24, 35, 18, 43, 64, 69, 10, 30, 62])       ],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['actual_seq'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "818d320b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>seq</th>\n",
       "      <th>rep_token_first_pos</th>\n",
       "      <th>query_token</th>\n",
       "      <th>target_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[19]</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[72]</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[87]</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[8]</td>\n",
       "      <td>-1</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[74]</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  seq_len   seq  rep_token_first_pos  query_token  target_val\n",
       "0      0        1  [19]                    0           19           1\n",
       "1      1        1  [72]                   -1           11           0\n",
       "2      2        1  [87]                    0           87           1\n",
       "3      3        1   [8]                   -1           35           0\n",
       "4      4        1  [74]                    0           74           1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2b9ab2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_val, df_test, ip_sequence_train_val, ip_sequence_test = train_test_split(\n",
    "    df, ip_sequence,\n",
    "    random_state=2,\n",
    "    test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "67b87ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, ip_sequence_train, ip_sequence_val = train_test_split(\n",
    "    df_train_val, ip_sequence_train_val,\n",
    "    random_state=2,\n",
    "    test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "73b9b23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                             185911\n",
       "seq_len                                                               96\n",
       "seq                    [47 98 11 82 55 89 46 27 28 24  4 71  2 95 81 ...\n",
       "rep_token_first_pos                                                   -1\n",
       "query_token                                                           59\n",
       "target_val                                                             0\n",
       "Name: 185911, dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.iloc[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d99d2dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47, 98, 11, 82, 55, 89, 46, 27, 28, 24,  4, 71,  2, 95, 81, 45, 73,\n",
       "       26, 68, 66, 64, 51, 65, 34, 44, 93, 43, 54, 38, 70, 79, 92,  9, 86,\n",
       "       20, 96,  5, 30, 42, 52, 41, 25,  3, 94,  7, 13, 97, 74, 48, 77, 56,\n",
       "       40, 33, 31, 61, 15, 88, 90, 91, 53, 57, 67, 72, 23, 18, 69, 85, 12,\n",
       "       14, 21, 83, 10, 17, 84, 19, 63, 37, 49, 78, 76, 99, 50, 36, 22, 29,\n",
       "       58, 80,  6, 16, 87, 62, 32, 39,  1, 75, 60, 59])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip_sequence_test[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6205b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df_test and ip_sequence_test for later analysis\n",
    "np.save('test_context_query.npy', ip_sequence_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cdd647f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_context_query.npy', ip_sequence_train)\n",
    "np.save('val_context_query.npy', ip_sequence_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a82c2436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_json('synthetic_train.json')\n",
    "df_val.to_json('synthetic_val.json')\n",
    "df_test.to_json('synthetic_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6cb1420",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_len = df['seq_len'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a04624d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sequence = df['seq'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd544af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_token_first_pos = df['rep_token_first_pos'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f131a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_repeated = df['query_token'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a642acd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_repeated[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "430f2a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_y = df['target_val'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56fd705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(INP_PATH + 'input_data.pkl', 'rb')\n",
    "x = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb79e182",
   "metadata": {},
   "outputs": [],
   "source": [
    "orth_vectors = np.load(\n",
    "    INP_PATH + 'orthonormal_vectors_512.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d991f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d65989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_sequence = np.load(INP_PATH + 'raw_sequence.npy',\n",
    "                allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb9c7903",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0aadd0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sample_length = len(raw_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3f2e8d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(max_seq_len, latent_dim, padding, memory_model, num_samples, x,\n",
    "                 raw_sequence):\n",
    "    # separate out the input to the encoder and the mlp\n",
    "    # mlp is fed the last one hot encoded input\n",
    "    x_mlp = [0] * num_samples\n",
    "    x_encoder = [0] * num_samples\n",
    "\n",
    "    for iter, seq in enumerate(x):\n",
    "        # seq[-1] - eos seq[-2] - query token seq[0:-2] - seq\n",
    "        x_mlp[iter] = seq[-2]\n",
    "        # all but the last one hot encoded sequence\n",
    "        x_encoder[iter] = seq[0:-2]\n",
    "        # eos\n",
    "        x_encoder[iter].append(seq[-1])\n",
    "\n",
    "    # seq len + 1 for alphabet + eos as orthonormal vectors are created with eos\n",
    "    # max size of seq len is not max seq len - 1 for the actual sequence + 1 for eos\n",
    "    encoder_input_data = np.zeros((num_samples, max_seq_len,\n",
    "                                   latent_dim * 2), dtype=\"float32\")\n",
    "\n",
    "    mlp_input_data = np.zeros((num_samples, latent_dim * 2), dtype=\"float32\")\n",
    "\n",
    "    if padding == 'pre_padding':\n",
    "        print(\"The shape of the encoder data is: \" + str(\n",
    "            encoder_input_data.shape))\n",
    "        for i in range(num_samples):\n",
    "            seq_len = len(x_encoder[i])\n",
    "\n",
    "            for seq in range(seq_len):\n",
    "                # fill the elements in encoder_input_data in the reverse order,\n",
    "                # this ensures that zero padding is done before the sequence\n",
    "                encoder_input_data[i, max_seq_len - seq_len + seq] = \\\n",
    "                    x_encoder[i][seq]\n",
    "            mlp_input_data[i] = x_mlp[i]\n",
    "    elif padding == 'post_padding':\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            seq_len = len(x_encoder[i])\n",
    "            for seq in range(seq_len):\n",
    "                encoder_input_data[i, seq] = x_encoder[i][seq]\n",
    "            mlp_input_data[i] = x_mlp[i]\n",
    "\n",
    "    if memory_model == \"transformer_no_orthonormal\":\n",
    "        # remove the query token - the last token in raw_sequence\n",
    "        sequence_raw = []\n",
    "        for seq in raw_sequence:\n",
    "            sequence_raw.append(seq[:-1])\n",
    "        raw_sequence_padded = keras.preprocessing.sequence.pad_sequences(\n",
    "            sequence_raw, maxlen=max_seq_len - 1, value=0)\n",
    "    else:\n",
    "        raw_sequence_padded = raw_sequence\n",
    "\n",
    "    return encoder_input_data, mlp_input_data, raw_sequence_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3006956",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 100\n",
    "latent_dim=256\n",
    "nn_model = \"lstm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "52cf022d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[72]'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_sequence[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d3618f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the encoder data is: (193714, 100, 512)\n"
     ]
    }
   ],
   "source": [
    "encoder_input_data, query_data, raw_sequence_padded = \\\n",
    "    process_data(max_seq_len, latent_dim, \"pre_padding\",\n",
    "                     nn_model, num_samples,\n",
    "                     x, raw_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "28cf49a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "(encoder_input_data_train, encoder_input_data_test,\n",
    " query_train, query_test,\n",
    " target_y_train, target_y_test,\n",
    " sequence_len_train, sequence_len_test,\n",
    " token_repeated_train, token_repeated_test,\n",
    " rep_token_first_pos_train, rep_token_first_pos_test,\n",
    " raw_sequence_train, raw_sequence_test) = train_test_split(\n",
    "    encoder_input_data,\n",
    "    query_data,\n",
    "    target_y,\n",
    "    sequence_len,\n",
    "    token_repeated,\n",
    "    rep_token_first_pos,\n",
    "    raw_sequence_padded,\n",
    "    random_state=2,\n",
    "    test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "30d30bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train val split\n",
    "(encoder_input_train, encoder_input_val,\n",
    " query_input_train, query_input_val,\n",
    " target_train, target_val,\n",
    " sequence_length_train, sequence_length_val,\n",
    " token_rep_train, token_rep_val,\n",
    " rep_token_pos_train, rep_token_pos_val,\n",
    " raw_seq_train, raw_seq_val) = train_test_split(\n",
    "    encoder_input_data_train,\n",
    "    query_train,\n",
    "    target_y_train,\n",
    "    sequence_len_train,\n",
    "    token_repeated_train,\n",
    "    rep_token_first_pos_train,\n",
    "    raw_sequence_train,\n",
    "    random_state=2,\n",
    "    test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bad76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath_cnn = '/data/sherin/checkpoint_synthetic/best_model_CNN'\n",
    "checkpoint_filepath_lstm = '/data/sherin/checkpoint_synthetic/best_model_lstm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc33e2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 18:19:57.473850: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-06-23 18:19:57.474013: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-06-23 18:19:57.474105: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-06-23 18:19:57.474186: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-06-23 18:19:57.474263: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-06-23 18:19:57.474338: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-06-23 18:19:57.474417: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-06-23 18:19:57.474434: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-06-23 18:19:57.475194: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained model\n",
    "model = keras.models.load_model(checkpoint_filepath_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5be4ef20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, None, 512)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, None, 128)    196736      ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, None, 256)    98560       ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, None, 512)    393728      ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 512)         0           ['conv1d_2[0][0]']               \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['global_max_pooling1d[0][0]']   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          262656      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_op_layer_Mul (TensorFlowOpL  (None, 512)         0           ['dense[0][0]',                  \n",
      " ayer)                                                            'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " tf_op_layer_Sum (TensorFlowOpL  (None,)             0           ['tf_op_layer_Mul[0][0]']        \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " tf_op_layer_Reshape (TensorFlo  (None, 1)           0           ['tf_op_layer_Sum[0][0]']        \n",
      " wOpLayer)                                                                                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 951,680\n",
      "Trainable params: 951,680\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6140bb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    z = np.exp(-1.0 * x)\n",
    "    sig = 1.0 / (1.0 + z)\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "980fdcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(model, target_val, encoder_input_val,\n",
    "                  query_input_val):\n",
    "\n",
    "    y_test = model.predict([encoder_input_val, query_input_val])\n",
    "    y_test = sigmoid(y_test)\n",
    "    # y_pred = np.argmax(y_test, axis=1)\n",
    "    # for the kernel functions you would need values which are not 0 or 1\n",
    "    y_pred_binary = np.array([1 if y > 0.5 else 0 for y in y_test])\n",
    "    y_pred_continuous = y_test\n",
    "    return y_pred_binary, y_pred_continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "08a0d32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1817/1817 [==============================] - 13s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_binary, y_pred_continuous = predict_model(model, target_y_test,\n",
    "                                         encoder_input_data_test, query_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cb8881bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_pred_continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d4fc831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.tensor(y_pred_binary), 'syn_cnn_pred_label.pt')\n",
    "torch.save(torch.tensor(y_pred_continuous), 'syn_cnn_pred.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "668d6eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "model_lstm = keras.models.load_model(checkpoint_filepath_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e38dccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, None, 512)]  0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 240),        722880      ['input_3[0][0]']                \n",
      "                                 (None, 240),                                                     \n",
      "                                 (None, 240)]                                                     \n",
      "                                                                                                  \n",
      " tf_op_layer_concat (TensorFlow  (None, 480)         0           ['lstm[0][1]',                   \n",
      " OpLayer)                                                         'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          246272      ['tf_op_layer_concat[0][0]']     \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_op_layer_Mul (TensorFlowOpL  (None, 512)         0           ['dense[0][0]',                  \n",
      " ayer)                                                            'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " tf_op_layer_Sum (TensorFlowOpL  (None,)             0           ['tf_op_layer_Mul[0][0]']        \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " tf_op_layer_Reshape (TensorFlo  (None, 1)           0           ['tf_op_layer_Sum[0][0]']        \n",
      " wOpLayer)                                                                                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 969,152\n",
      "Trainable params: 969,152\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7a1d2407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1817/1817 [==============================] - 108s 59ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tf14/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_pred_binary, y_pred_continuous = predict_model(model_lstm, target_y_test,\n",
    "                                         encoder_input_data_test, query_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "881b4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.tensor(y_pred_binary), 'syn_lstm_pred_label.pt')\n",
    "torch.save(torch.tensor(y_pred_continuous), 'syn_lstm_pred.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "05c17502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1272/1272 [==============================] - 75s 59ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tf14/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "lstm_y_pred_binary, lstm_y_pred_continuous = predict_model(model_lstm, target_val,\n",
    "                                         encoder_input_val, query_input_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fe46c4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1272/1272 [==============================] - 9s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "cnn_y_pred_binary, cnn_y_pred_continuous = predict_model(model, target_val,\n",
    "                                         encoder_input_val, query_input_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0c57023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.tensor(lstm_y_pred_binary), 'val_syn_lstm_pred_label.pt')\n",
    "torch.save(torch.tensor(lstm_y_pred_continuous), 'val_syn_lstm_pred.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e1843d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.tensor(cnn_y_pred_binary), 'val_syn_cnn_pred_label.pt')\n",
    "torch.save(torch.tensor(cnn_y_pred_continuous), 'val_syn_cnn_pred.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca225027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
