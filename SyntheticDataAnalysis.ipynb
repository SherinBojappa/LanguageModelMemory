{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08933a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749abc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_PATH = '/data/sherin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22722b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn = pd.read_pickle(INP_PATH + '/synthetic_inputs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac7ea327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data in our case is just numbers from 0 to 512 so we will write this in a file\n",
    "# pre-training a tokenizer - https://www.youtube.com/watch?v=cR4qMSIvX28&ab_channel=JamesBriggs\n",
    "from tqdm import tqdm\n",
    "\n",
    "text_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ba58664",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = [i for i in df_syn['sequence'].values.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "987f5eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer_file.txt', 'w') as f:\n",
    "    for a in seq:\n",
    "        s = \" \".join([str(v) for v in a])\n",
    "        f.write(s)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2294436f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in /opt/conda/envs/tf14/lib/python3.7/site-packages (0.11.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e7a05a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import BertWordPieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "16666663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Len of vocab in this way is 116\n",
    "#tokenizer = BertWordPieceTokenizer(clean_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "66734c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tokenizer.train(files='tokenizer_file.txt', vocab_size=520, min_frequency=1, \n",
    "#                special_tokens=['[PAD]', '[UNK]', '[CLS]', '[SEP]','[MASK]'], \n",
    "#                wordpieces_prefix = '##')\n",
    "                                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "34183a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./vocab.txt']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizer.save_model('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe250f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fa414b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd5e4858",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_tokenized_data.txt', 'w') as fp:\n",
    "    for i in range(512):\n",
    "        fp.write(str(i))\n",
    "        fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90b9a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_new = BertWordPieceTokenizer(clean_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8688d4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# retain this tokenizer as it has more number of tokens\n",
    "tokenizer_new.train(files='new_tokenized_data.txt', vocab_size=600, min_frequency=1, \n",
    "                special_tokens=['[PAD]', '[UNK]', '[CLS]', '[SEP]','[MASK]'], \n",
    "                wordpieces_prefix = '##')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73402af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./vocab.txt']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_new.save_model('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7055ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./vocab.txt', 'r') as fp:\n",
    "    vocab = fp.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c692885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a040b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7c054f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 32, 42, 52, 3], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('10 20 30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8c7348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_token_id = tokenizer.convert_tokens_to_ids('[MASK]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68e6593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLM training pipeline\n",
    "#https://www.youtube.com/watch?v=heTYbpr9mD8&list=PLIUOU7oqGTLj-k75kkirRrCybsJzCKCJW&index=3&ab_channel=JamesBriggs\n",
    "#https://towardsdatascience.com/how-to-train-a-bert-model-from-scratch-72cfce554fc6\n",
    "import torch\n",
    "def MaskLanguageModelling(t):\n",
    "    rand = torch.rand(t.shape)\n",
    "    masks = (rand < 0.15)*(t > 2)\n",
    "    for i in range(t.shape[0]):\n",
    "        selection = torch.flatten(masks[i].nonzero()).tolist()\n",
    "        t[i, selection] = mask_token_id\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "69230582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the masked input will be in input_ids, you also need to specify the attention mask using mask, and labels which\n",
    "# are the actual input ids without masking\n",
    "input_ids = []\n",
    "mask = []\n",
    "labels = []\n",
    "\n",
    "# all the inputs are in 'tokenized_file.txt'\n",
    "with open('tokenizer_file.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "sample = tokenizer(lines, max_length=512, padding='max_length', truncation=True, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "30ddb613",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.append(sample.input_ids)\n",
    "mask.append(sample.attention_mask)\n",
    "input_ids.append(MaskLanguageModelling(sample.input_ids.detach().clone()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "15054378",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.cat(input_ids)\n",
    "mask = torch.cat(mask)\n",
    "labels = torch.cat(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "380c0ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = {'input_ids': input_ids, 'attention_mask': mask, 'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5da31ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        # store encodings internally\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        # return the number of samples\n",
    "        return self.encodings['input_ids'].shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # return dictionary of input_ids, attention_mask, and labels for index i\n",
    "        return {key: tensor[i] for key, tensor in self.encodings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a88b8bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "46040fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b4851ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig\n",
    "\n",
    "config = BertConfig(\n",
    "    vocab_size=tokenizer.vocab_size,  # we align this to the tokenizer vocab_size\n",
    "    max_position_embeddings=514,\n",
    "    hidden_size=512,\n",
    "    num_attention_heads=4,\n",
    "    num_hidden_layers=2,\n",
    "    type_vocab_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34968983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM\n",
    "\n",
    "model_bert = BertForMaskedLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "76ddda5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetentionNetwork(\n",
       "  (linear): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (model_bert): BertForMaskedLM(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(527, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(514, 768)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): BertOnlyMLMHead(\n",
       "      (predictions): BertLMPredictionHead(\n",
       "        (transform): BertPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (transform_act_fn): GELUActivation()\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=768, out_features=527, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# and move our model over to the selected device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67ae5013",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_507167/1098981787.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "8d2ce636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tf14/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# activate training mode\n",
    "model.train()\n",
    "# initialize optimizer\n",
    "optim = AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e409ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/data/sherin/checkpoint_lm/chkpt_synthetic_bert_best.pt.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "e81680ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/12109 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'attention_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_506843/3171859287.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         outputs = model(input_ids, attention_mask=attention_mask,\n\u001b[0;32m---> 16\u001b[0;31m                         labels=labels)\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m# extract loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf14/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'attention_mask'"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "min_loss = np.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        labels=labels)\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    if loss.item() < min_loss:\n",
    "        print(\"saving best model\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optim.state_dict(),\n",
    "            'loss': loss,\n",
    "        }, checkpoint_path)\n",
    "        min_loss = loss.item()\n",
    "    else:\n",
    "        print(\"not saving the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2419da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the context and query to be string\n",
    "def convert_to_string(df, col_name):\n",
    "    seq = df[col_name].tolist()\n",
    "    return \" \".join([str(a) for a in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0bd09d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the context and query to be string\n",
    "def convert_query(df, col_name):\n",
    "    return(str(df[col_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9daeaaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_syn['seq_str'] = df_syn.apply(lambda x: convert_to_string(x, 'sequence'), axis=1)\n",
    "df_syn['query_str'] = df_syn.apply(lambda x: convert_query(x, 'query'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb78a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp = df_syn.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "b402de56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>query</th>\n",
       "      <th>sequence_len</th>\n",
       "      <th>first_rep_pos</th>\n",
       "      <th>label</th>\n",
       "      <th>token_repeated</th>\n",
       "      <th>seq_str</th>\n",
       "      <th>query_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>193730</th>\n",
       "      <td>[1, 13, 29, 12, 11, 88, 0, 48, 46, 87, 86, 76,...</td>\n",
       "      <td>94</td>\n",
       "      <td>99</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1 13 29 12 11 88 0 48 46 87 86 76 3 7 95 50 71...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193731</th>\n",
       "      <td>[55, 60, 11, 90, 18, 38, 9, 87, 35, 30, 6, 48,...</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>55 60 11 90 18 38 9 87 35 30 6 48 41 16 77 57 ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193732</th>\n",
       "      <td>[53, 54, 1, 44, 48, 79, 15, 47, 23, 58, 97, 33...</td>\n",
       "      <td>42</td>\n",
       "      <td>99</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>53 54 1 44 48 79 15 47 23 58 97 33 29 78 26 91...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193733</th>\n",
       "      <td>[36, 30, 49, 66, 52, 7, 79, 37, 62, 9, 59, 27,...</td>\n",
       "      <td>69</td>\n",
       "      <td>99</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>36 30 49 66 52 7 79 37 62 9 59 27 85 72 12 97 ...</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193734</th>\n",
       "      <td>[0, 84, 62, 7, 5, 18, 40, 63, 32, 68, 87, 66, ...</td>\n",
       "      <td>72</td>\n",
       "      <td>99</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0 84 62 7 5 18 40 63 32 68 87 66 93 90 13 8 37...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sequence  query  \\\n",
       "193730  [1, 13, 29, 12, 11, 88, 0, 48, 46, 87, 86, 76,...     94   \n",
       "193731  [55, 60, 11, 90, 18, 38, 9, 87, 35, 30, 6, 48,...      4   \n",
       "193732  [53, 54, 1, 44, 48, 79, 15, 47, 23, 58, 97, 33...     42   \n",
       "193733  [36, 30, 49, 66, 52, 7, 79, 37, 62, 9, 59, 27,...     69   \n",
       "193734  [0, 84, 62, 7, 5, 18, 40, 63, 32, 68, 87, 66, ...     72   \n",
       "\n",
       "        sequence_len  first_rep_pos  label  token_repeated  \\\n",
       "193730            99             -1      0              -1   \n",
       "193731            99             46      1               4   \n",
       "193732            99             -1      0              -1   \n",
       "193733            99             16      1              69   \n",
       "193734            99             -1      0              -1   \n",
       "\n",
       "                                                  seq_str query_str  \n",
       "193730  1 13 29 12 11 88 0 48 46 87 86 76 3 7 95 50 71...        94  \n",
       "193731  55 60 11 90 18 38 9 87 35 30 6 48 41 16 77 57 ...         4  \n",
       "193732  53 54 1 44 48 79 15 47 23 58 97 33 29 78 26 91...        42  \n",
       "193733  36 30 49 66 52 7 79 37 62 9 59 27 85 72 12 97 ...        69  \n",
       "193734  0 84 62 7 5 18 40 63 32 68 87 66 93 90 13 8 37...        72  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "9067d52d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193730    94\n",
       "193731     4\n",
       "193732    42\n",
       "193733    69\n",
       "193734    72\n",
       "Name: query_str, dtype: object"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp.head().iloc[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "810cf08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset with the dataframe\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe):\n",
    "\n",
    "        self.context = dataframe.iloc[:, 6]\n",
    "        self.query = dataframe.iloc[:,7]\n",
    "        self.labels = dataframe.iloc[:, 4]\n",
    "\n",
    "        #self.x_train=torch.tensor(x,dtype=torch.float32)\n",
    "        #self.y_train=torch.tensor(y,dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.query)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        #print(self.query[idx], self.labels[idx])\n",
    "        return self.context.iloc[idx], self.query.iloc[idx], self.labels.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7aa8b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "data_set = CustomDataset(df_syn)\n",
    "\n",
    "# split the dataset into train(80%), validation(10%), and test(10%)\n",
    "train_len = int(len(df_syn)*0.8)\n",
    "test_len = int(len(df_syn)*0.1)\n",
    "val_len = len(df_syn) - train_len - test_len\n",
    "train_set, val_set, test_set = random_split(data_set, [train_len, val_len, test_len])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set,batch_size=128,shuffle=True)\n",
    "test_loader = DataLoader(test_set,batch_size=128,shuffle=False)\n",
    "val_loader = DataLoader(val_set,batch_size=128,shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98ad970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b099adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetentionNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RetentionNetwork, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            # 384 is the size of the embedding\n",
    "            #nn.Linear(768, 768)\n",
    "            nn.Linear(512, 512, bias=False)\n",
    "        )\n",
    "        self.model_bert = BertForMaskedLM(config)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        #print(x.size())\n",
    "        x_tok = tokenizer(x, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "        x_bert = self.model_bert(**x_tok, output_hidden_states=True)\n",
    "        #print(len(x_bert.hidden_states))\n",
    "        x_bert_rep = x_bert.hidden_states[-1][:,0,:]\n",
    "        y_tok = tokenizer(y, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "        y_op = self.model_bert(**y_tok, output_hidden_states=True)\n",
    "        y_op_rep = y_op.hidden_states[-1][:,1,:]\n",
    "        x_op = self.linear(x_bert_rep)\n",
    "        #print(x_input.size())\n",
    "        #print(y.size())\n",
    "        op = torch.sum(x_op*y_op_rep, dim=1)\n",
    "        #print(op.shape)\n",
    "        return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "925968f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RetentionNetwork(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=False)\n",
      "  )\n",
      "  (model_bert): BertForMaskedLM(\n",
      "    (bert): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(527, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(514, 512)\n",
      "        (token_type_embeddings): Embedding(1, 512)\n",
      "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=512, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=512, bias=True)\n",
      "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=512, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=512, bias=True)\n",
      "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (cls): BertOnlyMLMHead(\n",
      "      (predictions): BertLMPredictionHead(\n",
      "        (transform): BertPredictionHeadTransform(\n",
      "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (transform_act_fn): GELUActivation()\n",
      "          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (decoder): Linear(in_features=512, out_features=527, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = RetentionNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1401f8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertOnlyMLMHead(\n",
       "  (predictions): BertLMPredictionHead(\n",
       "    (transform): BertPredictionHeadTransform(\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (transform_act_fn): GELUActivation()\n",
       "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): Linear(in_features=512, out_features=527, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_bert.cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "0732c59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear.0.weight True\n",
      "model_bert.bert.embeddings.word_embeddings.weight True\n",
      "model_bert.bert.embeddings.position_embeddings.weight True\n",
      "model_bert.bert.embeddings.token_type_embeddings.weight True\n",
      "model_bert.bert.embeddings.LayerNorm.weight True\n",
      "model_bert.bert.embeddings.LayerNorm.bias True\n",
      "model_bert.bert.encoder.layer.0.attention.self.query.weight True\n",
      "model_bert.bert.encoder.layer.0.attention.self.query.bias True\n",
      "model_bert.bert.encoder.layer.0.attention.self.key.weight True\n",
      "model_bert.bert.encoder.layer.0.attention.self.key.bias True\n",
      "model_bert.bert.encoder.layer.0.attention.self.value.weight True\n",
      "model_bert.bert.encoder.layer.0.attention.self.value.bias True\n",
      "model_bert.bert.encoder.layer.0.attention.output.dense.weight True\n",
      "model_bert.bert.encoder.layer.0.attention.output.dense.bias True\n",
      "model_bert.bert.encoder.layer.0.attention.output.LayerNorm.weight True\n",
      "model_bert.bert.encoder.layer.0.attention.output.LayerNorm.bias True\n",
      "model_bert.bert.encoder.layer.0.intermediate.dense.weight True\n",
      "model_bert.bert.encoder.layer.0.intermediate.dense.bias True\n",
      "model_bert.bert.encoder.layer.0.output.dense.weight True\n",
      "model_bert.bert.encoder.layer.0.output.dense.bias True\n",
      "model_bert.bert.encoder.layer.0.output.LayerNorm.weight True\n",
      "model_bert.bert.encoder.layer.0.output.LayerNorm.bias True\n",
      "model_bert.bert.encoder.layer.1.attention.self.query.weight True\n",
      "model_bert.bert.encoder.layer.1.attention.self.query.bias True\n",
      "model_bert.bert.encoder.layer.1.attention.self.key.weight True\n",
      "model_bert.bert.encoder.layer.1.attention.self.key.bias True\n",
      "model_bert.bert.encoder.layer.1.attention.self.value.weight True\n",
      "model_bert.bert.encoder.layer.1.attention.self.value.bias True\n",
      "model_bert.bert.encoder.layer.1.attention.output.dense.weight True\n",
      "model_bert.bert.encoder.layer.1.attention.output.dense.bias True\n",
      "model_bert.bert.encoder.layer.1.attention.output.LayerNorm.weight True\n",
      "model_bert.bert.encoder.layer.1.attention.output.LayerNorm.bias True\n",
      "model_bert.bert.encoder.layer.1.intermediate.dense.weight True\n",
      "model_bert.bert.encoder.layer.1.intermediate.dense.bias True\n",
      "model_bert.bert.encoder.layer.1.output.dense.weight True\n",
      "model_bert.bert.encoder.layer.1.output.dense.bias True\n",
      "model_bert.bert.encoder.layer.1.output.LayerNorm.weight True\n",
      "model_bert.bert.encoder.layer.1.output.LayerNorm.bias True\n",
      "model_bert.cls.predictions.bias True\n",
      "model_bert.cls.predictions.transform.dense.weight True\n",
      "model_bert.cls.predictions.transform.dense.bias True\n",
      "model_bert.cls.predictions.transform.LayerNorm.weight True\n",
      "model_bert.cls.predictions.transform.LayerNorm.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "        print(\"{} {}\".format(name, param.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25ee1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "\n",
    "#criterion = nn.functional.binary_cross_entropy()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcfc7d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1211 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|███████████████████████████████████████| 1211/1211 [02:55<00:00,  6.91it/s]\n",
      "100%|█████████████████████████████████████████| 152/152 [00:17<00:00,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'checkpoint_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_507167/80927046.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             }, checkpoint_path)\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mval_acc_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'checkpoint_path' is not defined"
     ]
    }
   ],
   "source": [
    "epoch_loss_list = []\n",
    "accuracy_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "valid_acc_max = 0 \n",
    "\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    train_count = 0\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    \n",
    "    #for ind in tqdm(range(len(df_short)))\n",
    "    for c, q, labels in tqdm(train_loader):\n",
    "        train_count = train_count+1\n",
    "        #context = torch.tensor(model_sent_trans.encode(list(c))).to(device)\n",
    "        #context = get_rep(c, is_context=True)\n",
    "        #print(context.size())\n",
    "        \n",
    "        #query = torch.tensor(model_sent_trans.encode(list(q))).to(device)\n",
    "        #query = get_rep(q, is_context=False)\n",
    "        \n",
    "        target = labels.to(device)\n",
    "        #label = torch.tensor(labels.float()).to(device)\n",
    "        label = labels.float().to(device)\n",
    "        #print(context.size())\n",
    "        #print(query.size())     \n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(c, q)\n",
    "        #loss = criterion(outputs, labels)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        #print(loss.item())\n",
    "        # print statistics\n",
    "        #running_loss += loss.item()\n",
    "        epoch_loss += loss.item()\n",
    "        accuracy += torchmetrics.functional.accuracy(outputs, target, threshold=0.5).item()\n",
    "        #if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "        #print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "        #running_loss = 0.0\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    \n",
    "    test_count = 0\n",
    "    for c, q, labels in tqdm(val_loader):\n",
    "        test_count = test_count + 1\n",
    "        #context = get_rep(c, is_context=True)\n",
    "        #query = get_rep(q, is_context=False)\n",
    "\n",
    "        target = labels.to(device)\n",
    "        label = labels.float().to(device)\n",
    "        \n",
    "        outputs = model(c, q)\n",
    "        loss = criterion(outputs, label)\n",
    "        val_loss += loss.item()\n",
    "        val_acc += torchmetrics.functional.accuracy(outputs, target, threshold=0.5).item()\n",
    "        \n",
    "    accuracy = accuracy / train_count\n",
    "    epoch_loss = epoch_loss / train_count\n",
    "    val_loss = val_loss / test_count\n",
    "    val_acc = val_acc / test_count\n",
    "    \n",
    "    if val_acc > valid_acc_max:\n",
    "        print(\"saving best model\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': val_loss,\n",
    "            'accuracy': val_acc,\n",
    "            }, checkpoint_path)\n",
    "        val_acc_max = val_acc\n",
    "    else:\n",
    "        print(\"not saving the model\")\n",
    "    \n",
    "    print(f'[{epoch + 1}, {i + 1:5d}] Training loss: {epoch_loss:.3f} Training accuracy : {accuracy:.3f}')\n",
    "    print(f'[{epoch + 1}, {i + 1:5d}] Validation loss: {val_loss:.3f} Validation accuracy : {val_acc:.3f}')\n",
    "    epoch_loss_list.append(epoch_loss)\n",
    "    accuracy_list.append(accuracy)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_acc_list.append(val_acc)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "1297025b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "78deabf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f48309371d0>]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "1d4f7c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f482f452350>]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "425138e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetentionNetwork(\n",
       "  (linear): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (model_bert): BertForMaskedLM(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(527, 512, padding_idx=0)\n",
       "        (position_embeddings): Embedding(514, 512)\n",
       "        (token_type_embeddings): Embedding(1, 512)\n",
       "        (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=512, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=512, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): BertOnlyMLMHead(\n",
       "      (predictions): BertLMPredictionHead(\n",
       "        (transform): BertPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (transform_act_fn): GELUActivation()\n",
       "          (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=512, out_features=527, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model = RetentionNetwork().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "PATH = checkpoint_path\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "# inferece\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "16ae7020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 152/152 [00:34<00:00,  4.43it/s]\n"
     ]
    }
   ],
   "source": [
    "test_count = 0\n",
    "output_logits = []\n",
    "for c, q, labels in tqdm(test_loader):\n",
    "\n",
    "    target = labels.to(device)\n",
    "    label = labels.float().to(device)\n",
    "    outputs = model(c, q).detach().cpu().numpy()\n",
    "        \n",
    "    outputs = model(c, q).detach().cpu().numpy()\n",
    "    output_logits.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "fa14152b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "6030b57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5001385513889162"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc_list[199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c6d947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
