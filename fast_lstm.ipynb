{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad22cb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -Uq fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a5a9f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e80984cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai\n",
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92d85eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "35f2f901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='190201856' class='' max='190200704' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [190201856/190200704 00:08<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = untar_data(URLs.WIKITEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b2a4e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(path/'train.csv', header=None)\n",
    "df_valid = pd.read_csv(path/'test.csv', header=None)\n",
    "df_all = pd.concat([df_train, df_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "deb14180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "splits = [list(range_of(df_train)), list(range(len(df_train), len(df_all)))]\n",
    "tfms = [attrgetter(\"text\"), Tokenizer.from_df(0), Numericalize()]\n",
    "dsets = Datasets(df_all, [tfms], splits=splits, dl_type=LMDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "347f5dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,sl = 5,512\n",
    "dls = dsets.dataloaders(bs=bs, seq_len=sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f11b7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "65fc2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = language_model_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=Perplexity(), pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4bd44885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [3.2393643856048584,25.517498016357422]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4f421437",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_memory = pd.read_pickle(\"balanced_inputs.pkl\")\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ef4f69da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fastai(x):\n",
    "    tokenized = np.zeros((len(df_memory), 512))\n",
    "    for idx, c in tqdm(enumerate(x)):\n",
    "        tokens = np.array(dsets.numericalize(dsets.tokenizer(c)).tolist())[:512]\n",
    "        tokenized[idx, 512-len(tokens):] = tokens\n",
    "    \n",
    "    return tokenized  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e1c447cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_fastai(tokenized):\n",
    "    count = 0\n",
    "    rep_list = []\n",
    "    while count < len(df_memory):\n",
    "        rep_list.append(lm.model[0](\n",
    "            torch.Tensor(tokenized[count:count+batch_size]).long().cuda()).detach().cpu().numpy()[:,-1,:])\n",
    "        count += batch_size\n",
    "        #print(count)\n",
    "        \n",
    "    return torch.tensor(np.vstack(rep_list))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8888d112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387216it [26:43, 241.52it/s]\n",
      "387216it [02:08, 3006.19it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_context = tokenize_fastai(df_memory['context'])\n",
    "tokenized_query= tokenize_fastai(df_memory['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "24b46485",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_context = rep_fastai(tokenized_context)\n",
    "X_query = rep_fastai(tokenized_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1f0eacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.tensor(df_memory['label'].values).float()\n",
    "target = torch.tensor(df_memory['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8d27b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "data_set = TensorDataset(X_context,X_query,label, target)\n",
    "\n",
    "train_len = int(len(data_set)*0.8)\n",
    "test_len = int(len(data_set)*0.1)\n",
    "val_len = len(data_set) - train_len - test_len\n",
    "train_set, val_set, test_set = random_split(data_set, [train_len, val_len, test_len])\n",
    "\n",
    "train_loader = DataLoader(train_set,batch_size=128,shuffle=True)\n",
    "test_loader = DataLoader(test_set,batch_size=128,shuffle=False)\n",
    "val_loader = DataLoader(val_set,batch_size=128,shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "43e7d82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/data/sherin/checkpoint_lm/chkpt_lm_lstm_fastai_recall_best.pt.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cd39960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "08e296ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            # 384 is the size of the embedding\n",
    "            nn.Linear(400, 400)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        #print(x.size())\n",
    "        x_input = self.linear(x)\n",
    "        #print(x_input.size())\n",
    "        #print(y.size())\n",
    "        op = torch.sum(x_input*y, dim=1)\n",
    "        #print(op.shape)\n",
    "        return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e0907890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=400, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f23cba4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#criterion = nn.functional.binary_cross_entropy()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5dfef2a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:14<00:00, 165.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:01<00:00, 267.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model\n",
      "[1] Training loss: 0.594 Training accuracy : 0.668\n",
      "[1] Validation loss: 0.535 Validation accuracy : 0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:13<00:00, 174.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:01<00:00, 265.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model\n",
      "[2] Training loss: 0.491 Training accuracy : 0.746\n",
      "[2] Validation loss: 0.487 Validation accuracy : 0.747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:12<00:00, 199.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:01<00:00, 266.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model\n",
      "[3] Training loss: 0.443 Training accuracy : 0.780\n",
      "[3] Validation loss: 0.458 Validation accuracy : 0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:12<00:00, 201.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:01<00:00, 282.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model\n",
      "[4] Training loss: 0.412 Training accuracy : 0.801\n",
      "[4] Validation loss: 0.431 Validation accuracy : 0.793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:11<00:00, 201.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:01<00:00, 277.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model\n",
      "[5] Training loss: 0.390 Training accuracy : 0.815\n",
      "[5] Validation loss: 0.421 Validation accuracy : 0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:12<00:00, 199.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:01<00:00, 272.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model\n",
      "[6] Training loss: 0.372 Training accuracy : 0.827\n",
      "[6] Validation loss: 0.417 Validation accuracy : 0.807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:12<00:00, 200.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:02<00:00, 112.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model\n",
      "[7] Training loss: 0.356 Training accuracy : 0.836\n",
      "[7] Validation loss: 0.406 Validation accuracy : 0.820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:12<00:00, 196.81it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:01<00:00, 273.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model\n",
      "[8] Training loss: 0.343 Training accuracy : 0.844\n",
      "[8] Validation loss: 0.397 Validation accuracy : 0.827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:12<00:00, 199.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:01<00:00, 272.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model\n",
      "[9] Training loss: 0.333 Training accuracy : 0.850\n",
      "[9] Validation loss: 0.377 Validation accuracy : 0.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:12<00:00, 197.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:01<00:00, 270.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model\n",
      "[10] Training loss: 0.323 Training accuracy : 0.855\n",
      "[10] Validation loss: 0.378 Validation accuracy : 0.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:12<00:00, 196.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:01<00:00, 257.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not saving the model\n",
      "[11] Training loss: 0.314 Training accuracy : 0.860\n",
      "[11] Validation loss: 0.384 Validation accuracy : 0.819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:11<00:00, 202.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:01<00:00, 279.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model\n",
      "[12] Training loss: 0.308 Training accuracy : 0.863\n",
      "[12] Validation loss: 0.373 Validation accuracy : 0.846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:12<00:00, 193.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:03<00:00, 93.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not saving the model\n",
      "[13] Training loss: 0.300 Training accuracy : 0.868\n",
      "[13] Validation loss: 0.367 Validation accuracy : 0.842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:11<00:00, 202.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:01<00:00, 278.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model\n",
      "[14] Training loss: 0.294 Training accuracy : 0.871\n",
      "[14] Validation loss: 0.369 Validation accuracy : 0.854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:12<00:00, 196.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:01<00:00, 259.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not saving the model\n",
      "[15] Training loss: 0.289 Training accuracy : 0.874\n",
      "[15] Validation loss: 0.369 Validation accuracy : 0.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:12<00:00, 200.84it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:01<00:00, 262.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not saving the model\n",
      "[16] Training loss: 0.283 Training accuracy : 0.876\n",
      "[16] Validation loss: 0.362 Validation accuracy : 0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:12<00:00, 198.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:01<00:00, 265.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model\n",
      "[17] Training loss: 0.278 Training accuracy : 0.879\n",
      "[17] Validation loss: 0.372 Validation accuracy : 0.860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:12<00:00, 200.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:01<00:00, 259.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not saving the model\n",
      "[18] Training loss: 0.273 Training accuracy : 0.881\n",
      "[18] Validation loss: 0.362 Validation accuracy : 0.858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:12<00:00, 196.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:02<00:00, 119.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not saving the model\n",
      "[19] Training loss: 0.270 Training accuracy : 0.884\n",
      "[19] Validation loss: 0.358 Validation accuracy : 0.848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2421/2421 [00:12<00:00, 199.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:01<00:00, 272.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model\n",
      "[20] Training loss: 0.266 Training accuracy : 0.885\n",
      "[20] Validation loss: 0.346 Validation accuracy : 0.861\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchmetrics\n",
    "\n",
    "epoch_loss_list = []\n",
    "accuracy_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "valid_acc_max = 0 \n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    train_count = 0\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    \n",
    "    #for ind in tqdm(range(len(df_short)))\n",
    "    for c, q, label, target in tqdm(train_loader):\n",
    "        train_count = train_count+1\n",
    "        #context = torch.tensor(model_sent_trans.encode(list(c))).to(device)\n",
    "        context = c.to(device)\n",
    "        \n",
    "        #query = torch.tensor(model_sent_trans.encode(list(q))).to(device)\n",
    "        query = q.to(device)\n",
    "        \n",
    "        target = target.to(device)\n",
    "        #label = torch.tensor(labels.float()).to(device)\n",
    "        label = label.to(device)\n",
    "        #print(context.size())\n",
    "        #print(query.size())     \n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(context, query)\n",
    "        #loss = criterion(outputs, labels)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        #print(loss.item())\n",
    "        # print statistics\n",
    "        #running_loss += loss.item()\n",
    "        epoch_loss += loss.item()\n",
    "        accuracy += torchmetrics.functional.accuracy(outputs, target, threshold=0.5).item()\n",
    "        #if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "        #print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "        #running_loss = 0.0\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    \n",
    "    test_count = 0\n",
    "    for c, q, label, target in tqdm(val_loader):\n",
    "        test_count = test_count + 1\n",
    "        context = c.to(device)\n",
    "        query = q.to(device)\n",
    "        \n",
    "        target = target.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        outputs = model(context, query)\n",
    "        loss = criterion(outputs, label)\n",
    "        val_loss += loss.item()\n",
    "        val_acc += torchmetrics.functional.accuracy(outputs, target, threshold=0.5).item()\n",
    "        \n",
    "    accuracy = accuracy / train_count\n",
    "    epoch_loss = epoch_loss / train_count\n",
    "    val_loss = val_loss / test_count\n",
    "    val_acc = val_acc / test_count\n",
    "    \n",
    "    if val_acc > valid_acc_max:\n",
    "        print(\"saving best model\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': val_loss,\n",
    "            'accuracy': val_acc,\n",
    "            }, checkpoint_path)\n",
    "        valid_acc_max = val_acc\n",
    "    else:\n",
    "        print(\"not saving the model\")\n",
    "    \n",
    "    print(f'[{epoch + 1}] Training loss: {epoch_loss:.3f} Training accuracy : {accuracy:.3f}')\n",
    "    print(f'[{epoch + 1}] Validation loss: {val_loss:.3f} Validation accuracy : {val_acc:.3f}')\n",
    "    epoch_loss_list.append(epoch_loss)\n",
    "    accuracy_list.append(accuracy)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_acc_list.append(val_acc)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "03ae7cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (linear): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=400, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "PATH = checkpoint_path\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "# inferece\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "68ee37ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 303/303 [00:00<00:00, 405.75it/s]\n"
     ]
    }
   ],
   "source": [
    "test_count = 0\n",
    "output_logits = []\n",
    "for c, q, label, target in tqdm(test_loader):\n",
    "    context = c.to(device)\n",
    "    query = q.to(device)\n",
    "    target = target.to(device)\n",
    "    label = label.to(device)\n",
    "        \n",
    "    outputs = model(context, query).detach().cpu().numpy()\n",
    "    output_logits.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c3470960",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output_logits = np.hstack(output_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5032548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_lstm = df_memory.iloc[test_loader.dataset.indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f17e16e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38721,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6a777347",
   "metadata": {},
   "outputs": [
    {
     "ename": "SettingWithCopyError",
     "evalue": "\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSettingWithCopyError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_509109/3673109845.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_test_lstm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lstm_pred\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_output_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/tf14/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3610\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3611\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3612\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3614\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf14/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3795\u001b[0m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexisting_piece\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3797\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3799\u001b[0m     def _set_value(\n",
      "\u001b[0;32m/opt/conda/envs/tf14/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item_mgr\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3760\u001b[0m         \u001b[0;31m# value exception to occur first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3762\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iset_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/tf14/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_check_setitem_copy\u001b[0;34m(self, stacklevel, t, force)\u001b[0m\n\u001b[1;32m   3931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3932\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3933\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSettingWithCopyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3934\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"warn\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3935\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSettingWithCopyWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSettingWithCopyError\u001b[0m: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy"
     ]
    }
   ],
   "source": [
    "df_test_lstm[\"pred\"] = torch.sigmoid(torch.tensor(test_output_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3e6575",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_lstm[\"lstm_pred_label\"] = 1.0 * (df_test_lstm[\"bert_pred\"] > 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
