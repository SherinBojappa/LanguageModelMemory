{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a008ec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65a2c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# make sure that test_df has the results of bert and lstm horizontally attached, because you need to average \n",
    "# accuracies for a particular word\n",
    "df_memory = pd.read_pickle(\"test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a294b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_memory.to_csv('test_df.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbfafbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35033"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c628fa87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['query',\n",
       " 'context',\n",
       " 'label',\n",
       " 'context_length',\n",
       " 'valence',\n",
       " 'arousal',\n",
       " 'dominance',\n",
       " 'num_meanings',\n",
       " 'num_rep',\n",
       " 'int_tok',\n",
       " 'tokenized_context_length',\n",
       " 'bert_pred',\n",
       " 'bert_pred_label',\n",
       " 'bert_conf_of_correct_class',\n",
       " 'success',\n",
       " 'query_lemma',\n",
       " 'query_pos',\n",
       " 'count',\n",
       " 'count_bin_id',\n",
       " 'valence_id',\n",
       " 'arousal_id',\n",
       " 'dominance_id']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_memory.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63603dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new columns for VAD, count, num_meanings normalized\n",
    "df_memory[\"valence\"] = pd.to_numeric(df_memory[\"valence\"])\n",
    "df_memory[\"arousal\"] = pd.to_numeric(df_memory[\"arousal\"])\n",
    "df_memory[\"dominance\"] = pd.to_numeric(df_memory[\"dominance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aaccb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee826d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = df_memory['query_pos'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4199cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert query_pos which is a string into a categorical variable\n",
    "df_memory['query_pos_categorical']= df_memory['query_pos'].replace(tags,\n",
    "                        range(0, len(tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bcbff9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_success_rate = df_memory.groupby([\"query\"], group_keys=False).apply(lambda x: x['success'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5254d09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6111111111111112"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_success_rate['navy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "34c92187",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_memory_unique = df_memory.drop_duplicates('query', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8be4e92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1954"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_memory_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e055186a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tf14/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_memory_unique['avg_accuracy'] = df_memory_unique.apply(lambda x: query_success_rate[x['query']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cefa9810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>context</th>\n",
       "      <th>label</th>\n",
       "      <th>context_length</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "      <th>num_meanings</th>\n",
       "      <th>num_rep</th>\n",
       "      <th>int_tok</th>\n",
       "      <th>...</th>\n",
       "      <th>query_lemma</th>\n",
       "      <th>query_pos</th>\n",
       "      <th>count</th>\n",
       "      <th>count_bin_id</th>\n",
       "      <th>valence_id</th>\n",
       "      <th>arousal_id</th>\n",
       "      <th>dominance_id</th>\n",
       "      <th>valence_normalized</th>\n",
       "      <th>query_pos_categorical</th>\n",
       "      <th>avg_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>belief</td>\n",
       "      <td>Vitellius began his reign with a large funeral...</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.656</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>belief</td>\n",
       "      <td>NN</td>\n",
       "      <td>12108114</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.703021</td>\n",
       "      <td>0</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first</td>\n",
       "      <td>In 2015 UPM was ranked 41st in the UI World Un...</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.788</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>first</td>\n",
       "      <td>JJ</td>\n",
       "      <td>578161543</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.257049</td>\n",
       "      <td>1</td>\n",
       "      <td>0.785796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capacity</td>\n",
       "      <td>Currently , 45 of Malaysian natural gas is fou...</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.806</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>capacity</td>\n",
       "      <td>NN</td>\n",
       "      <td>48726947</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.758604</td>\n",
       "      <td>0</td>\n",
       "      <td>0.892857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>small</td>\n",
       "      <td>However , the airstrip was heavily bombed by A...</td>\n",
       "      <td>1</td>\n",
       "      <td>409</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.120</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "      <td>...</td>\n",
       "      <td>small</td>\n",
       "      <td>JJ</td>\n",
       "      <td>208371878</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.185813</td>\n",
       "      <td>1</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>navy</td>\n",
       "      <td>Though the ships were laid down in 1873 their ...</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.764</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>navy</td>\n",
       "      <td>JJ</td>\n",
       "      <td>22018379</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.244506</td>\n",
       "      <td>1</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      query                                            context  label  \\\n",
       "0    belief  Vitellius began his reign with a large funeral...      1   \n",
       "1     first  In 2015 UPM was ranked 41st in the UI World Un...      0   \n",
       "2  capacity  Currently , 45 of Malaysian natural gas is fou...      1   \n",
       "3     small  However , the airstrip was heavily bombed by A...      1   \n",
       "4      navy  Though the ships were laid down in 1873 their ...      1   \n",
       "\n",
       "   context_length  valence  arousal  dominance  num_meanings  num_rep  \\\n",
       "0              47    0.896    0.375      0.656             2        1   \n",
       "1              98    0.625    0.500      0.788            16        0   \n",
       "2             132    0.719    0.411      0.806             9        1   \n",
       "3             409    0.542    0.205      0.120            13        1   \n",
       "4              44    0.531    0.760      0.764             3        1   \n",
       "\n",
       "   int_tok  ...  query_lemma  query_pos      count  count_bin_id  valence_id  \\\n",
       "0       18  ...       belief         NN   12108114             0           8   \n",
       "1       -1  ...        first         JJ  578161543             4           6   \n",
       "2       61  ...     capacity         NN   48726947             0           7   \n",
       "3      209  ...        small         JJ  208371878             1           5   \n",
       "4       23  ...         navy         JJ   22018379             0           5   \n",
       "\n",
       "  arousal_id dominance_id  valence_normalized  query_pos_categorical  \\\n",
       "0          3            6            1.703021                      0   \n",
       "1          4            7            0.257049                      1   \n",
       "2          3            8            0.758604                      0   \n",
       "3          1            0           -0.185813                      1   \n",
       "4          7            7           -0.244506                      1   \n",
       "\n",
       "   avg_accuracy  \n",
       "0      0.944444  \n",
       "1      0.785796  \n",
       "2      0.892857  \n",
       "3      0.909091  \n",
       "4      0.611111  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_memory_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "81d6f61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = df_memory_unique[[\"valence\",\"arousal\",\"dominance\", \"num_meanings\", \"query_pos_categorical\", \"count\"]].values\n",
    "features = df_memory_unique[[\"query_pos_categorical\"]].values\n",
    "\n",
    "#features = df_memory_unique[[\"context_length\", \"int_tok\", \"num_rep\"]].values\n",
    "#features = df_memory_unique[[\"context_length\"]].values\n",
    "words = df_memory_unique['query'].values\n",
    "target_accuracy = df_memory_unique['avg_accuracy'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "4729beda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1954"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "8817e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = target_accuracy<1.0\n",
    "target_accuracy = target_accuracy[ids]\n",
    "features = features[ids]\n",
    "words = words[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "5bcebd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 48.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,\n",
       "          0.,   3.,   0.,   1.,   1.,  28.,   0.,   1.,   0.,   7.,   4.,\n",
       "          6.,   1.,   0., 120.,   1.,   6.,  11.,   4.,  28.,  23.,  12.,\n",
       "        117.,  39.,  32.,  26., 108.,  67.,  45., 142.,  98., 101.,  71.,\n",
       "         53.,  75.,  34.,  21.,  11., 608.]),\n",
       " array([0.  , 0.02, 0.04, 0.06, 0.08, 0.1 , 0.12, 0.14, 0.16, 0.18, 0.2 ,\n",
       "        0.22, 0.24, 0.26, 0.28, 0.3 , 0.32, 0.34, 0.36, 0.38, 0.4 , 0.42,\n",
       "        0.44, 0.46, 0.48, 0.5 , 0.52, 0.54, 0.56, 0.58, 0.6 , 0.62, 0.64,\n",
       "        0.66, 0.68, 0.7 , 0.72, 0.74, 0.76, 0.78, 0.8 , 0.82, 0.84, 0.86,\n",
       "        0.88, 0.9 , 0.92, 0.94, 0.96, 0.98, 1.  ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(target_accuracy, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "6337950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(features_scaled_train_val, features_scaled_test, \n",
    "target_accuracy_train_val, target_accuracy_test,\n",
    "words_train_val, words_test) =  train_test_split(features, target_accuracy, words, \n",
    "                                                                random_state=2, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "4909e1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(features_scaled_train, features_scaled_val, \n",
    " target_accuracy_train, target_accuracy_val,\n",
    " words_train, words_val) = train_test_split(features_scaled_train_val, \n",
    "                                                                target_accuracy_train_val,\n",
    "                                                                words_train_val,\n",
    "                                                                random_state=2, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "d38de5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the dataset - https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "# std in scaler.scale_\n",
    "# mean in scaler.mean_\n",
    "scaler = preprocessing.StandardScaler().fit(features_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "d2d283ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_scaled_train = scaler.transform(features_scaled_train)\n",
    "features_scaled_val = scaler.transform(features_scaled_val)\n",
    "features_scaled_test = scaler.transform(features_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "332e6373",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " R^2 score: -0.12076708220307064\n",
      " mse score: 0.04569889101835418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tf14/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/opt/conda/envs/tf14/lib/python3.7/site-packages/sklearn/utils/fixes.py:223: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "/opt/conda/envs/tf14/lib/python3.7/site-packages/sklearn/ensemble/base.py:158: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int)\n",
      "/opt/conda/envs/tf14/lib/python3.7/site-packages/sklearn/utils/fixes.py:223: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n",
      "/opt/conda/envs/tf14/lib/python3.7/site-packages/sklearn/ensemble/base.py:158: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int)\n",
      "/opt/conda/envs/tf14/lib/python3.7/site-packages/sklearn/utils/fixes.py:223: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if _joblib.__version__ >= LooseVersion('0.12'):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "lr = RandomForestRegressor().fit(features_scaled_train, target_accuracy_train)\n",
    "pred_accuracy_test = lr.predict(features_scaled_test)\n",
    "print(f\" R^2 score: {lr.score(features_scaled_test, target_accuracy_test)}\")\n",
    "print(f\" mse score: {np.sum((pred_accuracy_test - target_accuracy_test)**2)/len(pred_accuracy_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "6e8216fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " R^2 score: -0.003235539902542328\n",
      " mse score: 0.04135309252368285\n",
      " spearman : -0.029509068865170848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "lr = LinearRegression().fit(features_scaled_train, target_accuracy_train)\n",
    "pred_accuracy_test = lr.predict(features_scaled_test)\n",
    "print(f\" R^2 score: {lr.score(features_scaled_test, target_accuracy_test)}\")\n",
    "print(f\" mse score: {np.sum((pred_accuracy_test - target_accuracy_test)**2)/len(pred_accuracy_test)}\")\n",
    "print(f\" spearman : {stats.spearmanr(pred_accuracy_test, target_accuracy_test)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "a209461c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f6fa0cd3250>"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(target_accuracy_test, pred_accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "31cd21c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6924eaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a linear regression model\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(linearRegression, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(6, 30)\n",
    "        self.fc2 = torch.nn.Linear(30, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = F.sigmoid(self.fc2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b9ff363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "8d7d49aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearRegression(\n",
      "  (fc1): Linear(in_features=6, out_features=30, bias=True)\n",
      "  (fc2): Linear(in_features=30, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = linearRegression().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "6d754e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f8644797",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "53ad89db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save checkpoint\n",
    "# https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "#https://towardsdatascience.com/how-to-save-and-load-a-model-in-pytorch-with-a-complete-example-c2920e617dee\n",
    "checkpoint_path = '/data/sherin/checkpoint_lm/linear_regression_best.pt.tar'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b1e6bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = torch.tensor(features_scaled_train).to(device)\n",
    "targets_train = torch.tensor(target_accuracy_train).to(device)\n",
    "\n",
    "inputs_val = torch.tensor(features_scaled_val).to(device)\n",
    "targets_val = torch.tensor(target_accuracy_val).to(device)\n",
    "\n",
    "inputs_test = torch.tensor(features_scaled_test).to(device)\n",
    "targets_test = torch.tensor(target_accuracy_test).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "9fad7192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tf14/lib/python3.7/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/opt/conda/envs/tf14/lib/python3.7/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([847])) that is different to the input size (torch.Size([847, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/conda/envs/tf14/lib/python3.7/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([95])) that is different to the input size (torch.Size([95, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0958, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 0, loss 0.09212551265954971\n",
      "tensor(0.0943, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 1, loss 0.09050619602203369\n",
      "tensor(0.0929, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 2, loss 0.0889202207326889\n",
      "tensor(0.0914, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 3, loss 0.08735788613557816\n",
      "tensor(0.0900, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 4, loss 0.08582020550966263\n",
      "tensor(0.0886, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 5, loss 0.08432962000370026\n",
      "tensor(0.0872, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 6, loss 0.08286651968955994\n",
      "tensor(0.0859, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 7, loss 0.0814373642206192\n",
      "tensor(0.0846, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 8, loss 0.08003067970275879\n",
      "tensor(0.0833, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 9, loss 0.07866016030311584\n",
      "tensor(0.0821, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 10, loss 0.07731734961271286\n",
      "tensor(0.0808, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 11, loss 0.07600710541009903\n",
      "tensor(0.0796, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 12, loss 0.07472414523363113\n",
      "tensor(0.0785, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 13, loss 0.07347972691059113\n",
      "tensor(0.0773, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 14, loss 0.07226011902093887\n",
      "tensor(0.0762, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 15, loss 0.07108305394649506\n",
      "tensor(0.0751, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 16, loss 0.06992657482624054\n",
      "tensor(0.0741, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 17, loss 0.06880173832178116\n",
      "tensor(0.0730, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 18, loss 0.06770388036966324\n",
      "tensor(0.0720, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 19, loss 0.06663154810667038\n",
      "tensor(0.0710, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 20, loss 0.06559554487466812\n",
      "tensor(0.0701, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 21, loss 0.06457871943712234\n",
      "tensor(0.0692, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 22, loss 0.06359350681304932\n",
      "tensor(0.0683, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 23, loss 0.06262869387865067\n",
      "tensor(0.0674, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 24, loss 0.061687979847192764\n",
      "tensor(0.0665, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 25, loss 0.06077977642416954\n",
      "tensor(0.0657, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 26, loss 0.059893153607845306\n",
      "tensor(0.0649, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 27, loss 0.05903056636452675\n",
      "tensor(0.0641, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 28, loss 0.05818702280521393\n",
      "tensor(0.0633, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 29, loss 0.057373370975255966\n",
      "tensor(0.0626, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 30, loss 0.05657920613884926\n",
      "tensor(0.0619, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 31, loss 0.05580161511898041\n",
      "tensor(0.0612, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 32, loss 0.05504980310797691\n",
      "tensor(0.0605, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 33, loss 0.05431031063199043\n",
      "tensor(0.0598, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 34, loss 0.053601618856191635\n",
      "tensor(0.0592, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 35, loss 0.052903298288583755\n",
      "tensor(0.0586, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 36, loss 0.052231211215257645\n",
      "tensor(0.0580, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 37, loss 0.05157973989844322\n",
      "tensor(0.0574, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 38, loss 0.050935450941324234\n",
      "tensor(0.0568, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 39, loss 0.05031992122530937\n",
      "tensor(0.0563, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 40, loss 0.04971414431929588\n",
      "tensor(0.0557, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 41, loss 0.049131233245134354\n",
      "tensor(0.0552, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 42, loss 0.0485638789832592\n",
      "tensor(0.0547, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 43, loss 0.048007525503635406\n",
      "tensor(0.0542, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 44, loss 0.047469716519117355\n",
      "tensor(0.0538, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 45, loss 0.04694916307926178\n",
      "tensor(0.0533, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 46, loss 0.046440787613391876\n",
      "tensor(0.0529, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 47, loss 0.045948732644319534\n",
      "tensor(0.0524, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 48, loss 0.04546862468123436\n",
      "tensor(0.0520, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 49, loss 0.04499977454543114\n",
      "tensor(0.0516, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 50, loss 0.04454784095287323\n",
      "tensor(0.0512, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 51, loss 0.04411071166396141\n",
      "tensor(0.0508, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 52, loss 0.0436834879219532\n",
      "tensor(0.0505, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 53, loss 0.043270956724882126\n",
      "tensor(0.0501, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 54, loss 0.042865559458732605\n",
      "tensor(0.0498, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 55, loss 0.042472582310438156\n",
      "tensor(0.0495, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 56, loss 0.04209285229444504\n",
      "tensor(0.0491, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 57, loss 0.04172501340508461\n",
      "tensor(0.0488, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 58, loss 0.041366398334503174\n",
      "tensor(0.0485, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 59, loss 0.0410127155482769\n",
      "tensor(0.0482, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 60, loss 0.0406801775097847\n",
      "tensor(0.0480, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 61, loss 0.04034833610057831\n",
      "tensor(0.0477, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 62, loss 0.040031567215919495\n",
      "tensor(0.0474, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 63, loss 0.039720628410577774\n",
      "tensor(0.0472, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 64, loss 0.03942286968231201\n",
      "tensor(0.0469, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 65, loss 0.039131779223680496\n",
      "tensor(0.0467, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 66, loss 0.03885003551840782\n",
      "tensor(0.0465, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 67, loss 0.038577280938625336\n",
      "tensor(0.0463, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 68, loss 0.0383131168782711\n",
      "tensor(0.0460, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 69, loss 0.03805354982614517\n",
      "tensor(0.0458, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 70, loss 0.037806641310453415\n",
      "tensor(0.0456, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 71, loss 0.03756321221590042\n",
      "tensor(0.0454, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 72, loss 0.03733294829726219\n",
      "tensor(0.0453, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 73, loss 0.037103261798620224\n",
      "tensor(0.0451, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 74, loss 0.036885686218738556\n",
      "tensor(0.0449, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 75, loss 0.03667202591896057\n",
      "tensor(0.0448, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 76, loss 0.036466218531131744\n",
      "tensor(0.0446, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 77, loss 0.036268483847379684\n",
      "tensor(0.0444, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 78, loss 0.036075666546821594\n",
      "tensor(0.0443, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 79, loss 0.035890236496925354\n",
      "tensor(0.0442, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 80, loss 0.035707566887140274\n",
      "tensor(0.0440, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 81, loss 0.03553559631109238\n",
      "tensor(0.0439, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 82, loss 0.03536655008792877\n",
      "tensor(0.0438, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 83, loss 0.035203784704208374\n",
      "tensor(0.0437, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 84, loss 0.03504599630832672\n",
      "tensor(0.0435, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 85, loss 0.03489398583769798\n",
      "tensor(0.0434, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 86, loss 0.03474640101194382\n",
      "tensor(0.0433, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 87, loss 0.03460536524653435\n",
      "tensor(0.0432, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 88, loss 0.03446920961141586\n",
      "tensor(0.0431, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 89, loss 0.034336455166339874\n",
      "tensor(0.0430, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 90, loss 0.034206733107566833\n",
      "tensor(0.0429, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 91, loss 0.034083977341651917\n",
      "tensor(0.0428, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 92, loss 0.03396407142281532\n",
      "tensor(0.0428, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 93, loss 0.03384935483336449\n",
      "tensor(0.0427, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 94, loss 0.03373849019408226\n",
      "tensor(0.0426, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 95, loss 0.03363092243671417\n",
      "tensor(0.0425, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 96, loss 0.03352660313248634\n",
      "tensor(0.0425, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 97, loss 0.03342564404010773\n",
      "tensor(0.0424, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 98, loss 0.03332941606640816\n",
      "tensor(0.0423, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 99, loss 0.03323671221733093\n",
      "tensor(0.0423, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model\n",
      "epoch 100, loss 0.033145442605018616\n",
      "tensor(0.0422, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 101, loss 0.03305881842970848\n",
      "tensor(0.0422, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 102, loss 0.03297619894146919\n",
      "tensor(0.0421, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 103, loss 0.03289565071463585\n",
      "tensor(0.0420, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 104, loss 0.032815366983413696\n",
      "tensor(0.0420, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 105, loss 0.03274013474583626\n",
      "tensor(0.0419, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 106, loss 0.03266942501068115\n",
      "tensor(0.0419, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 107, loss 0.03259871527552605\n",
      "tensor(0.0419, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 108, loss 0.03253309056162834\n",
      "tensor(0.0418, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 109, loss 0.03246790170669556\n",
      "tensor(0.0418, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 110, loss 0.032405830919742584\n",
      "tensor(0.0417, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 111, loss 0.03234650939702988\n",
      "tensor(0.0417, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 112, loss 0.0322878398001194\n",
      "tensor(0.0417, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 113, loss 0.03223225846886635\n",
      "tensor(0.0416, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 114, loss 0.03217911720275879\n",
      "tensor(0.0416, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 115, loss 0.032126329839229584\n",
      "tensor(0.0416, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 116, loss 0.03207758814096451\n",
      "tensor(0.0416, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 117, loss 0.03202949836850166\n",
      "tensor(0.0415, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 118, loss 0.031983956694602966\n",
      "tensor(0.0415, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 119, loss 0.031938713043928146\n",
      "tensor(0.0415, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 120, loss 0.031896039843559265\n",
      "tensor(0.0414, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 121, loss 0.031855836510658264\n",
      "tensor(0.0414, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 122, loss 0.03181695193052292\n",
      "tensor(0.0414, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 123, loss 0.031777478754520416\n",
      "tensor(0.0414, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 124, loss 0.031740669161081314\n",
      "tensor(0.0414, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 125, loss 0.03170609846711159\n",
      "tensor(0.0413, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 126, loss 0.03167145699262619\n",
      "tensor(0.0413, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 127, loss 0.03163838014006615\n",
      "tensor(0.0413, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 128, loss 0.031608182936906815\n",
      "tensor(0.0413, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 129, loss 0.03157607838511467\n",
      "tensor(0.0413, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 130, loss 0.03154658526182175\n",
      "tensor(0.0413, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 131, loss 0.03151995316147804\n",
      "tensor(0.0413, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 132, loss 0.03149191662669182\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 133, loss 0.0314653180539608\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 134, loss 0.03144069388508797\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 135, loss 0.031416479498147964\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 136, loss 0.031392283737659454\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 137, loss 0.03136993199586868\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 138, loss 0.03134812414646149\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 139, loss 0.03132648393511772\n",
      "tensor(0.0412, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 140, loss 0.03130669146776199\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 141, loss 0.031287115067243576\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 142, loss 0.03126706928014755\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 143, loss 0.03124881722033024\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 144, loss 0.031232047826051712\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 145, loss 0.03121383860707283\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 146, loss 0.031197503209114075\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 147, loss 0.031181026250123978\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 148, loss 0.031165720894932747\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 149, loss 0.031151384115219116\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 150, loss 0.03113505430519581\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 151, loss 0.031121626496315002\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 152, loss 0.031108468770980835\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 153, loss 0.031094791367650032\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 154, loss 0.031082693487405777\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 155, loss 0.03106939047574997\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 156, loss 0.031057342886924744\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 157, loss 0.031045537441968918\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 158, loss 0.031033838167786598\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 159, loss 0.031022587791085243\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 160, loss 0.031011519953608513\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 161, loss 0.031001728028059006\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 162, loss 0.030991092324256897\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 163, loss 0.030980972573161125\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 164, loss 0.03097054362297058\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 165, loss 0.030961934477090836\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 166, loss 0.03095262125134468\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 167, loss 0.030943281948566437\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 168, loss 0.03093513287603855\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 169, loss 0.030925855040550232\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 170, loss 0.030917350202798843\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 171, loss 0.030908994376659393\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 172, loss 0.030901186168193817\n",
      "tensor(0.0410, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 173, loss 0.030893811956048012\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 174, loss 0.030885746702551842\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 175, loss 0.030878324061632156\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 176, loss 0.03087078407406807\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 177, loss 0.030864616855978966\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 178, loss 0.03085685893893242\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 179, loss 0.03085065446794033\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 180, loss 0.03084324300289154\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 181, loss 0.030836837366223335\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 182, loss 0.030830057337880135\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 183, loss 0.03082462027668953\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 184, loss 0.030817776918411255\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 185, loss 0.03081171028316021\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 186, loss 0.030805805698037148\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 187, loss 0.030799604952335358\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 188, loss 0.03079388663172722\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 189, loss 0.03078858181834221\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 190, loss 0.030782170593738556\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 191, loss 0.030778085812926292\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 192, loss 0.030771853402256966\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 193, loss 0.030765993520617485\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 194, loss 0.030761495232582092\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 195, loss 0.0307560246437788\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 196, loss 0.03075171262025833\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 197, loss 0.03074592724442482\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 198, loss 0.030741650611162186\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 199, loss 0.03073633462190628\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 200, loss 0.03073154203593731\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 201, loss 0.03072761371731758\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 202, loss 0.030721567571163177\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 203, loss 0.03071766532957554\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 204, loss 0.03071250207722187\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 205, loss 0.030707811936736107\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model\n",
      "epoch 206, loss 0.03070366010069847\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 207, loss 0.030698958784341812\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 208, loss 0.030695253983139992\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 209, loss 0.030690403655171394\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 210, loss 0.030686156824231148\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 211, loss 0.030681882053613663\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 212, loss 0.030677540227770805\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 213, loss 0.030672907829284668\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 214, loss 0.030669452622532845\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 215, loss 0.030664881691336632\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 216, loss 0.03066151589155197\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 217, loss 0.030657658353447914\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 218, loss 0.030653782188892365\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 219, loss 0.0306495763361454\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 220, loss 0.030646543949842453\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 221, loss 0.030642082914710045\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 222, loss 0.030637681484222412\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 223, loss 0.03063393384218216\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 224, loss 0.03063013404607773\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 225, loss 0.03062635287642479\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 226, loss 0.030622782185673714\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 227, loss 0.03061864897608757\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 228, loss 0.03061503916978836\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 229, loss 0.03061169758439064\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 230, loss 0.03060765378177166\n",
      "tensor(0.0408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 231, loss 0.030603714287281036\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 232, loss 0.03060046397149563\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 233, loss 0.030596589669585228\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 234, loss 0.030593177303671837\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 235, loss 0.03058934025466442\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 236, loss 0.03058543987572193\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 237, loss 0.03058278001844883\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 238, loss 0.03057931736111641\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 239, loss 0.030575212091207504\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 240, loss 0.030572084710001945\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 241, loss 0.030568407848477364\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 242, loss 0.030564865097403526\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 243, loss 0.030561473220586777\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 244, loss 0.030559075996279716\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 245, loss 0.030554212629795074\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 246, loss 0.030551331117749214\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 247, loss 0.030547697097063065\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 248, loss 0.03054414689540863\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 249, loss 0.030540481209754944\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 250, loss 0.030537258833646774\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 251, loss 0.030534112825989723\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 252, loss 0.030530065298080444\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 253, loss 0.030526822432875633\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 254, loss 0.03052421286702156\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 255, loss 0.030520576983690262\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 256, loss 0.030517075210809708\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 257, loss 0.03051433153450489\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 258, loss 0.030510105192661285\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 259, loss 0.030507126823067665\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 260, loss 0.030503850430250168\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 261, loss 0.03050043433904648\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 262, loss 0.030496416613459587\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 263, loss 0.03049362823367119\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 264, loss 0.030489854514598846\n",
      "tensor(0.0407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 265, loss 0.030486982315778732\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 266, loss 0.030483117327094078\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 267, loss 0.0304801594465971\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 268, loss 0.03047676384449005\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 269, loss 0.030473774299025536\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 270, loss 0.030471062287688255\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 271, loss 0.030467258766293526\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 272, loss 0.030464475974440575\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 273, loss 0.03046083077788353\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 274, loss 0.03045772947371006\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 275, loss 0.030454689636826515\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 276, loss 0.030451267957687378\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 277, loss 0.03044751100242138\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 278, loss 0.030445026233792305\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 279, loss 0.03044130653142929\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 280, loss 0.03043847344815731\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 281, loss 0.030435368418693542\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 282, loss 0.03043125383555889\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 283, loss 0.030428335070610046\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 284, loss 0.030425487086176872\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 285, loss 0.030422188341617584\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 286, loss 0.03041948191821575\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 287, loss 0.03041638247668743\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 288, loss 0.030412821099162102\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 289, loss 0.030409494414925575\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 290, loss 0.03040630742907524\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 291, loss 0.03040388785302639\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 292, loss 0.03039967454969883\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 293, loss 0.03039724938571453\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 294, loss 0.03039412759244442\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 295, loss 0.030390551313757896\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 296, loss 0.030387645587325096\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 297, loss 0.03038458526134491\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 298, loss 0.030381010845303535\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 299, loss 0.03037790022790432\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 300, loss 0.030374975875020027\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 301, loss 0.03037145920097828\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 302, loss 0.030368942767381668\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 303, loss 0.03036670759320259\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 304, loss 0.030362261459231377\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 305, loss 0.03035987727344036\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 306, loss 0.030356695875525475\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 307, loss 0.03035329468548298\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 308, loss 0.03035004809498787\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 309, loss 0.030347103253006935\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 310, loss 0.030343791469931602\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 311, loss 0.03034098632633686\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 312, loss 0.03033813089132309\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 313, loss 0.03033493272960186\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 314, loss 0.030331412330269814\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 315, loss 0.030329495668411255\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 316, loss 0.030326133593916893\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 317, loss 0.030322570353746414\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 318, loss 0.03032028116285801\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 319, loss 0.03031679429113865\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 320, loss 0.030313832685351372\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 321, loss 0.03031110018491745\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 322, loss 0.03030761145055294\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 323, loss 0.030304692685604095\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 324, loss 0.03030211851000786\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 325, loss 0.030298683792352676\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 326, loss 0.03029559925198555\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 327, loss 0.030292799696326256\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 328, loss 0.03028949350118637\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 329, loss 0.030287129804491997\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 330, loss 0.03028455190360546\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 331, loss 0.03028116002678871\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 332, loss 0.030278421938419342\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 333, loss 0.030276020988821983\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 334, loss 0.03027236834168434\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 335, loss 0.03026997111737728\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 336, loss 0.03026711381971836\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 337, loss 0.0302639901638031\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 338, loss 0.030260547995567322\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 339, loss 0.03025851584970951\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 340, loss 0.030255455523729324\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 341, loss 0.03025210089981556\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 342, loss 0.030250554904341698\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 343, loss 0.030246593058109283\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 344, loss 0.030244342982769012\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 345, loss 0.030242180451750755\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 346, loss 0.030238527804613113\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 347, loss 0.030236048623919487\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 348, loss 0.030233066529035568\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 349, loss 0.030229885131120682\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 350, loss 0.030226808041334152\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 351, loss 0.03022485226392746\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 352, loss 0.03022182360291481\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 353, loss 0.030218787491321564\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 354, loss 0.030216971412301064\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 355, loss 0.030213220044970512\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 356, loss 0.030210867524147034\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 357, loss 0.030208401381969452\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 358, loss 0.030204925686120987\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 359, loss 0.030202722176909447\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 360, loss 0.030199790373444557\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 361, loss 0.030196601524949074\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 362, loss 0.030194880440831184\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 363, loss 0.03019149787724018\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 364, loss 0.03018842078745365\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 365, loss 0.030185649171471596\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 366, loss 0.030183095484972\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 367, loss 0.030179927125573158\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 368, loss 0.03017847053706646\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 369, loss 0.03017563931643963\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 370, loss 0.03017258644104004\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 371, loss 0.03017023578286171\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 372, loss 0.030167611315846443\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 373, loss 0.03016452118754387\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 374, loss 0.030162695795297623\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 375, loss 0.030158840119838715\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 376, loss 0.0301569364964962\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 377, loss 0.030153825879096985\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 378, loss 0.03015112690627575\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 379, loss 0.030148973688483238\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 380, loss 0.030146677047014236\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 381, loss 0.0301443412899971\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 382, loss 0.030142061412334442\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 383, loss 0.03013903833925724\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 384, loss 0.030136192217469215\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 385, loss 0.030134053900837898\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 386, loss 0.030131423845887184\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 387, loss 0.030128633603453636\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 388, loss 0.030126282945275307\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 389, loss 0.030124390497803688\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 390, loss 0.03012075088918209\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 391, loss 0.03011789359152317\n",
      "tensor(0.0404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 392, loss 0.030116809532046318\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 393, loss 0.030114028602838516\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 394, loss 0.03011157363653183\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 395, loss 0.030108662322163582\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 396, loss 0.03010605275630951\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 397, loss 0.030103523284196854\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 398, loss 0.03010111302137375\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 399, loss 0.030098360031843185\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 400, loss 0.03009522147476673\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 401, loss 0.030092649161815643\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 402, loss 0.030090654268860817\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 403, loss 0.03008812479674816\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 404, loss 0.0300853680819273\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 405, loss 0.03008272685110569\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 406, loss 0.030080880969762802\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 407, loss 0.030077870935201645\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 408, loss 0.030075568705797195\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 409, loss 0.030073627829551697\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 410, loss 0.030070841312408447\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 411, loss 0.030067838728427887\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 412, loss 0.030065594241023064\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 413, loss 0.030062861740589142\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 414, loss 0.030060697346925735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 415, loss 0.030057646334171295\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 416, loss 0.030054772272706032\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 417, loss 0.030053414404392242\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 418, loss 0.03005085326731205\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 419, loss 0.03004857897758484\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 420, loss 0.030046746134757996\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 421, loss 0.03004414215683937\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 422, loss 0.03004075586795807\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 423, loss 0.030038535594940186\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 424, loss 0.030036138370633125\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 425, loss 0.030034085735678673\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 426, loss 0.030031872913241386\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 427, loss 0.030028268694877625\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 428, loss 0.030026348307728767\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 429, loss 0.030023785308003426\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 430, loss 0.03002188168466091\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 431, loss 0.0300199743360281\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 432, loss 0.030017713084816933\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 433, loss 0.030014608055353165\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 434, loss 0.030012713745236397\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 435, loss 0.03001013770699501\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 436, loss 0.030007923021912575\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 437, loss 0.030006391927599907\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 438, loss 0.03000216744840145\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 439, loss 0.030000122264027596\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 440, loss 0.029998749494552612\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 441, loss 0.029995854943990707\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 442, loss 0.029993968084454536\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 443, loss 0.029992662370204926\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 444, loss 0.029988862574100494\n",
      "tensor(0.0403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 445, loss 0.0299873948097229\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 446, loss 0.029984628781676292\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 447, loss 0.02998257987201214\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 448, loss 0.029980989173054695\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 449, loss 0.029978392645716667\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 450, loss 0.029975708574056625\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 451, loss 0.029974572360515594\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 452, loss 0.029971474781632423\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 453, loss 0.029970131814479828\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 454, loss 0.02996857278048992\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 455, loss 0.02996475249528885\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 456, loss 0.029964309185743332\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 457, loss 0.029962070286273956\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 458, loss 0.029959892854094505\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 459, loss 0.029958374798297882\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 460, loss 0.02995573729276657\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 461, loss 0.029953528195619583\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 462, loss 0.02995114214718342\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 463, loss 0.029949041083455086\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 464, loss 0.029947621747851372\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 465, loss 0.029945271089673042\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 466, loss 0.02994351275265217\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 467, loss 0.029940659180283546\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 468, loss 0.029939116910099983\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 469, loss 0.029937544837594032\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 470, loss 0.029935786500573158\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 471, loss 0.029933393001556396\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 472, loss 0.029931701719760895\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 473, loss 0.029928699135780334\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 474, loss 0.029927214607596397\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 475, loss 0.02992452308535576\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 476, loss 0.02992318384349346\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 477, loss 0.029921067878603935\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 478, loss 0.029918866232037544\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 479, loss 0.02991691790521145\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 480, loss 0.02991379424929619\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 481, loss 0.029911920428276062\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 482, loss 0.029911398887634277\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 483, loss 0.029908934608101845\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 484, loss 0.029907550662755966\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 485, loss 0.029905036091804504\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 486, loss 0.029902731999754906\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 487, loss 0.029901620000600815\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 488, loss 0.029899483546614647\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 489, loss 0.029896818101406097\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 490, loss 0.029895635321736336\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 491, loss 0.02989278733730316\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 492, loss 0.029890766367316246\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 493, loss 0.029889406636357307\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 494, loss 0.029887448996305466\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 495, loss 0.029885530471801758\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 496, loss 0.029884688556194305\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 497, loss 0.02988196723163128\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 498, loss 0.029880022630095482\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 499, loss 0.02987781912088394\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 500, loss 0.029876070097088814\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 501, loss 0.02987474389374256\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 502, loss 0.029872486367821693\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 503, loss 0.02987089566886425\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 504, loss 0.029868880286812782\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 505, loss 0.029867000877857208\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 506, loss 0.029864955693483353\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 507, loss 0.02986317314207554\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 508, loss 0.0298615712672472\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 509, loss 0.029859859496355057\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 510, loss 0.02985830418765545\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 511, loss 0.029856501147150993\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 512, loss 0.02985483407974243\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 513, loss 0.029852941632270813\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 514, loss 0.029851365834474564\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 515, loss 0.0298493430018425\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 516, loss 0.029846834018826485\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 517, loss 0.029846008867025375\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 518, loss 0.02984357438981533\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 519, loss 0.029842209070920944\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 520, loss 0.02984124794602394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 521, loss 0.029838839545845985\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 522, loss 0.029837412759661674\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 523, loss 0.02983466163277626\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 524, loss 0.029833253473043442\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 525, loss 0.029832005500793457\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 526, loss 0.02983037382364273\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 527, loss 0.02982865460216999\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 528, loss 0.029827434569597244\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 529, loss 0.029824262484908104\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 530, loss 0.02982310950756073\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 531, loss 0.02982180379331112\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 532, loss 0.029819900169968605\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 533, loss 0.029818030074238777\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 534, loss 0.029816651716828346\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 535, loss 0.029814479872584343\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 536, loss 0.029812384396791458\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 537, loss 0.029811231419444084\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 538, loss 0.029809266328811646\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 539, loss 0.029808184131979942\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 540, loss 0.02980731800198555\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 541, loss 0.029805555939674377\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 542, loss 0.02980303019285202\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 543, loss 0.029801296070218086\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 544, loss 0.02979903109371662\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 545, loss 0.02979792095720768\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 546, loss 0.029796700924634933\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 547, loss 0.02979545295238495\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 548, loss 0.02979383058845997\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 549, loss 0.029791634529829025\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 550, loss 0.02978941798210144\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 551, loss 0.029788071289658546\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 552, loss 0.029786156490445137\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 553, loss 0.029784588143229485\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 554, loss 0.02978329360485077\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 555, loss 0.029781771823763847\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 556, loss 0.02978047914803028\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 557, loss 0.0297788605093956\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 558, loss 0.02977772429585457\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 559, loss 0.02977612055838108\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 560, loss 0.02977425418794155\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 561, loss 0.02977304346859455\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 562, loss 0.029770970344543457\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 563, loss 0.02976907417178154\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 564, loss 0.0297677181661129\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 565, loss 0.029765507206320763\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 566, loss 0.02976471185684204\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 567, loss 0.02976331301033497\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 568, loss 0.029761318117380142\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 569, loss 0.029760140925645828\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 570, loss 0.029758334159851074\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 571, loss 0.02975565940141678\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 572, loss 0.02975487895309925\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 573, loss 0.029753871262073517\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 574, loss 0.02975202538073063\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 575, loss 0.02975078672170639\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 576, loss 0.029749367386102676\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 577, loss 0.029747195541858673\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 578, loss 0.029745901003479958\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 579, loss 0.02974456176161766\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 580, loss 0.029743071645498276\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 581, loss 0.02974078431725502\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 582, loss 0.029739994555711746\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 583, loss 0.029738498851656914\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 584, loss 0.029735956341028214\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 585, loss 0.029735015705227852\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 586, loss 0.029733767732977867\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 587, loss 0.029731661081314087\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 588, loss 0.02973095141351223\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 589, loss 0.029729412868618965\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 590, loss 0.02972779981791973\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 591, loss 0.02972579188644886\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 592, loss 0.02972453460097313\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 593, loss 0.029723038896918297\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 594, loss 0.02972206473350525\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 595, loss 0.029720868915319443\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 596, loss 0.029719414189457893\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 597, loss 0.029717717319726944\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 598, loss 0.02971605584025383\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 599, loss 0.029714176431298256\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 600, loss 0.02971290796995163\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 601, loss 0.029712408781051636\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 602, loss 0.02971048653125763\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 603, loss 0.029708653688430786\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 604, loss 0.029707856476306915\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 605, loss 0.029706118628382683\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 606, loss 0.02970416471362114\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 607, loss 0.02970327064394951\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 608, loss 0.029700977727770805\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 609, loss 0.029700160026550293\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 610, loss 0.029699595645070076\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 611, loss 0.029698779806494713\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 612, loss 0.029697241261601448\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 613, loss 0.029696054756641388\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 614, loss 0.029694441705942154\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 615, loss 0.02969290316104889\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 616, loss 0.029691537842154503\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 617, loss 0.029690559953451157\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 618, loss 0.029688920825719833\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 619, loss 0.02968822792172432\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 620, loss 0.029687030240893364\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 621, loss 0.029684653505682945\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 622, loss 0.02968340925872326\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 623, loss 0.029682353138923645\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 624, loss 0.02968081831932068\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving best model\n",
      "epoch 625, loss 0.029680058360099792\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 626, loss 0.029678918421268463\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 627, loss 0.029677558690309525\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 628, loss 0.029676305130124092\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 629, loss 0.029674163088202477\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 630, loss 0.029673298820853233\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 631, loss 0.029671674594283104\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 632, loss 0.02967073768377304\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 633, loss 0.029670754447579384\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 634, loss 0.029669571667909622\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 635, loss 0.029668107628822327\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 636, loss 0.029667090624570847\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 637, loss 0.0296647772192955\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 638, loss 0.02966386452317238\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 639, loss 0.0296635664999485\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 640, loss 0.029661348089575768\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 641, loss 0.02966049686074257\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 642, loss 0.029659414663910866\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 643, loss 0.029658101499080658\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 644, loss 0.02965688519179821\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 645, loss 0.029656264930963516\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 646, loss 0.029654396697878838\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 647, loss 0.029652992263436317\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 648, loss 0.029651440680027008\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 649, loss 0.029650984331965446\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 650, loss 0.029650183394551277\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 651, loss 0.029648441821336746\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 652, loss 0.029647666960954666\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 653, loss 0.029646841809153557\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 654, loss 0.02964409627020359\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 655, loss 0.0296431016176939\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 656, loss 0.029642906039953232\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 657, loss 0.029641591012477875\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 658, loss 0.029640857130289078\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 659, loss 0.02963954024016857\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 660, loss 0.029639078304171562\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 661, loss 0.029637502506375313\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 662, loss 0.0296364463865757\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 663, loss 0.029635107144713402\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 664, loss 0.02963389828801155\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 665, loss 0.02963240258395672\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 666, loss 0.029631929472088814\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 667, loss 0.029631273820996284\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 668, loss 0.029629284515976906\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 669, loss 0.02962862327694893\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 670, loss 0.029627172276377678\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 671, loss 0.029626497998833656\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 672, loss 0.02962455525994301\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 673, loss 0.029623469337821007\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 674, loss 0.02962321974337101\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 675, loss 0.029622001573443413\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 676, loss 0.029620736837387085\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 677, loss 0.029619982466101646\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 678, loss 0.029618944972753525\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 679, loss 0.029617788270115852\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 680, loss 0.02961813285946846\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 681, loss 0.029616279527544975\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 682, loss 0.02961498498916626\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 683, loss 0.029614051803946495\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 684, loss 0.029612870886921883\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 685, loss 0.029612019658088684\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 686, loss 0.029611075296998024\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 687, loss 0.029610315337777138\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 688, loss 0.029609626159071922\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 689, loss 0.029608583077788353\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 690, loss 0.029606694355607033\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 691, loss 0.029606139287352562\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 692, loss 0.029604850336909294\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 693, loss 0.029603634029626846\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 694, loss 0.029603498056530952\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 695, loss 0.029602831229567528\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 696, loss 0.029601145535707474\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 697, loss 0.029600759968161583\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 698, loss 0.029599832370877266\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 699, loss 0.029598811641335487\n",
      "tensor(0.0400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 700, loss 0.029596704989671707\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 701, loss 0.029596403241157532\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 702, loss 0.029594942927360535\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 703, loss 0.029595335945487022\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 704, loss 0.02959388867020607\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 705, loss 0.029593732208013535\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 706, loss 0.029592927545309067\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 707, loss 0.029591327533125877\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 708, loss 0.029591135680675507\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 709, loss 0.02958953008055687\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 710, loss 0.0295887254178524\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 711, loss 0.029587889090180397\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 712, loss 0.029587166383862495\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 713, loss 0.029586246237158775\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 714, loss 0.029585015028715134\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 715, loss 0.029584897682070732\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 716, loss 0.029583554714918137\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 717, loss 0.029583066701889038\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 718, loss 0.029581796377897263\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 719, loss 0.029580246657133102\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 720, loss 0.029579855501651764\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 721, loss 0.029579387977719307\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 722, loss 0.029577985405921936\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 723, loss 0.029577169567346573\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 724, loss 0.029577065259218216\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 725, loss 0.029576348140835762\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 726, loss 0.02957512065768242\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 727, loss 0.02957461029291153\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 728, loss 0.029574070125818253\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 729, loss 0.029572784900665283\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 730, loss 0.029572632163763046\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 731, loss 0.029571617022156715\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 732, loss 0.02957111783325672\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 733, loss 0.029570555314421654\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 734, loss 0.029569510370492935\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 735, loss 0.02956860512495041\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 736, loss 0.029568161815404892\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 737, loss 0.029566962271928787\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 738, loss 0.02956651896238327\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 739, loss 0.029566051438450813\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 740, loss 0.02956405095756054\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 741, loss 0.029563570395112038\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 742, loss 0.02956286072731018\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 743, loss 0.02956235222518444\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 744, loss 0.02956153079867363\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 745, loss 0.029560834169387817\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 746, loss 0.029559843242168427\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 747, loss 0.029559709131717682\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 748, loss 0.029558619484305382\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 749, loss 0.029557710513472557\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 750, loss 0.0295565165579319\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 751, loss 0.029556147754192352\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 752, loss 0.029555657878518105\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 753, loss 0.029553866013884544\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 754, loss 0.029554054141044617\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 755, loss 0.029552999883890152\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 756, loss 0.029552694410085678\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 757, loss 0.02955201268196106\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 758, loss 0.02955198846757412\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 759, loss 0.029551072046160698\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 760, loss 0.029550611972808838\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 761, loss 0.029548918828368187\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 762, loss 0.029548408463597298\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 763, loss 0.029547568410634995\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 764, loss 0.029547737911343575\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 765, loss 0.029545797035098076\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 766, loss 0.029546169564127922\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 767, loss 0.029545215889811516\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 768, loss 0.029544701799750328\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 769, loss 0.02954394742846489\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 770, loss 0.02954324148595333\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 771, loss 0.029542861506342888\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 772, loss 0.02954096533358097\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 773, loss 0.029540792107582092\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 774, loss 0.0295396838337183\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 775, loss 0.0295396838337183\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 776, loss 0.029538486152887344\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 777, loss 0.02953815460205078\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 778, loss 0.029537362977862358\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 779, loss 0.02953707054257393\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 780, loss 0.029536595568060875\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 781, loss 0.029535437002778053\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 782, loss 0.029535233974456787\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 783, loss 0.029534926638007164\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 784, loss 0.029533106833696365\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 785, loss 0.029533177614212036\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 786, loss 0.02953225187957287\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 787, loss 0.02953273057937622\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 788, loss 0.029531851410865784\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 789, loss 0.02953191287815571\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 790, loss 0.029531024396419525\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 791, loss 0.029530439525842667\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 792, loss 0.029529843479394913\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 793, loss 0.0295297559350729\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 794, loss 0.029528258368372917\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 795, loss 0.029528189450502396\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 796, loss 0.029527928680181503\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 797, loss 0.029526716098189354\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 798, loss 0.02952554263174534\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 799, loss 0.029525602236390114\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 800, loss 0.02952473796904087\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 801, loss 0.029524100944399834\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 802, loss 0.02952353097498417\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 803, loss 0.029522985219955444\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 804, loss 0.0295217577368021\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 805, loss 0.029521944001317024\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 806, loss 0.029521524906158447\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 807, loss 0.029520781710743904\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 808, loss 0.029520126059651375\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 809, loss 0.029518911615014076\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 810, loss 0.02951863780617714\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 811, loss 0.02951733209192753\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 812, loss 0.029517196118831635\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 813, loss 0.02951699309051037\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 814, loss 0.02951611392199993\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 815, loss 0.02951597236096859\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 816, loss 0.029515473172068596\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 817, loss 0.029515033587813377\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 818, loss 0.029515232890844345\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 819, loss 0.0295147355645895\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 820, loss 0.029514018446207047\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 821, loss 0.029513347893953323\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 822, loss 0.029513342306017876\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 823, loss 0.029511617496609688\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 824, loss 0.02951185405254364\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 825, loss 0.02951023168861866\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 826, loss 0.02951020374894142\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 827, loss 0.02951005846261978\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 828, loss 0.02950904332101345\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 829, loss 0.02950829640030861\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 830, loss 0.02950783632695675\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 831, loss 0.02950761467218399\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 832, loss 0.029506849125027657\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 833, loss 0.029506372287869453\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 834, loss 0.029505612328648567\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 835, loss 0.029505588114261627\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 836, loss 0.029504749923944473\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 837, loss 0.029503505676984787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 838, loss 0.029503880068659782\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 839, loss 0.02950190007686615\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 840, loss 0.029502008110284805\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 841, loss 0.029501618817448616\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 842, loss 0.029501628130674362\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 843, loss 0.029500072821974754\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 844, loss 0.02950034663081169\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 845, loss 0.029499812051653862\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 846, loss 0.02949957363307476\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 847, loss 0.029499098658561707\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 848, loss 0.029498327523469925\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 849, loss 0.029498310759663582\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 850, loss 0.029498230665922165\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 851, loss 0.029497861862182617\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 852, loss 0.02949768677353859\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 853, loss 0.02949625253677368\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 854, loss 0.029495244845747948\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 855, loss 0.029495324939489365\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 856, loss 0.029495328664779663\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 857, loss 0.02949441969394684\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 858, loss 0.029493989422917366\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 859, loss 0.029493337497115135\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 860, loss 0.029493188485503197\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 861, loss 0.02949279360473156\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 862, loss 0.02949126809835434\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 863, loss 0.02949119359254837\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 864, loss 0.029490750283002853\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 865, loss 0.029490429908037186\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 866, loss 0.02949005365371704\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 867, loss 0.02948884293437004\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 868, loss 0.02948852814733982\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 869, loss 0.029487237334251404\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 870, loss 0.029487399384379387\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 871, loss 0.029486533254384995\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 872, loss 0.02948642149567604\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 873, loss 0.029485313221812248\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 874, loss 0.02948532998561859\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 875, loss 0.02948501892387867\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 876, loss 0.02948448807001114\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 877, loss 0.029484160244464874\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 878, loss 0.029483584687113762\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 879, loss 0.02948324754834175\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 880, loss 0.029483327642083168\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 881, loss 0.029482262209057808\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 882, loss 0.02948218584060669\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 883, loss 0.02948182076215744\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 884, loss 0.02948087640106678\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 885, loss 0.02948153205215931\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 886, loss 0.029481036588549614\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 887, loss 0.029480954632163048\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 888, loss 0.029479295015335083\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 889, loss 0.02947862073779106\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 890, loss 0.02947918511927128\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 891, loss 0.029478654265403748\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 892, loss 0.029478462412953377\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 893, loss 0.029477134346961975\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 894, loss 0.02947699837386608\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 895, loss 0.029477329924702644\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 896, loss 0.029476841911673546\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 897, loss 0.02947543002665043\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 898, loss 0.02947518602013588\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 899, loss 0.029475023970007896\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 900, loss 0.02947518602013588\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 901, loss 0.02947450615465641\n",
      "tensor(0.0399, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 902, loss 0.029473237693309784\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 903, loss 0.02947349101305008\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 904, loss 0.029473137110471725\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 905, loss 0.029472723603248596\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 906, loss 0.0294718649238348\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 907, loss 0.029471976682543755\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 908, loss 0.029471581801772118\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 909, loss 0.029470479115843773\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 910, loss 0.029469255357980728\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 911, loss 0.029469572007656097\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 912, loss 0.029468879103660583\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 913, loss 0.029468653723597527\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 914, loss 0.029467904940247536\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 915, loss 0.029467323794960976\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 916, loss 0.029467353597283363\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 917, loss 0.029467381536960602\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 918, loss 0.02946672961115837\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 919, loss 0.029466502368450165\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 920, loss 0.029465893283486366\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 921, loss 0.029465775936841965\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 922, loss 0.029466820880770683\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 923, loss 0.029465988278388977\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 924, loss 0.029465412721037865\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 925, loss 0.02946506254374981\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 926, loss 0.029464898630976677\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 927, loss 0.029465068131685257\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 928, loss 0.02946503460407257\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 929, loss 0.029463471844792366\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 930, loss 0.02946365438401699\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 931, loss 0.029463790357112885\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 932, loss 0.029462704434990883\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 933, loss 0.029462389647960663\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 934, loss 0.029461031779646873\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 935, loss 0.029460854828357697\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 936, loss 0.029460668563842773\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 937, loss 0.029460111632943153\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 938, loss 0.029460564255714417\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 939, loss 0.029460124671459198\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 940, loss 0.029459303244948387\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 941, loss 0.029458805918693542\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 942, loss 0.02945903316140175\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 943, loss 0.029458029195666313\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 944, loss 0.029458176344633102\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 945, loss 0.029457608237862587\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 946, loss 0.02945692650973797\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 947, loss 0.02945721708238125\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 948, loss 0.029456432908773422\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not saving the model\n",
      "epoch 949, loss 0.02945651300251484\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 950, loss 0.029456064105033875\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 951, loss 0.029455553740262985\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 952, loss 0.029455499723553658\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 953, loss 0.029455045238137245\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 954, loss 0.02945484034717083\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 955, loss 0.029454492032527924\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 956, loss 0.02945425733923912\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 957, loss 0.02945350483059883\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 958, loss 0.029453294351696968\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 959, loss 0.029452936723828316\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 960, loss 0.029452083632349968\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 961, loss 0.029452381655573845\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 962, loss 0.029452191665768623\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 963, loss 0.029451116919517517\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 964, loss 0.029451441019773483\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 965, loss 0.02945135347545147\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 966, loss 0.02945132367312908\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 967, loss 0.029451332986354828\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 968, loss 0.029450926929712296\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 969, loss 0.02944999374449253\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 970, loss 0.02945001795887947\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 971, loss 0.02944980375468731\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 972, loss 0.02944977767765522\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 973, loss 0.029449405148625374\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 974, loss 0.02944837510585785\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 975, loss 0.029448429122567177\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 976, loss 0.029448246583342552\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 977, loss 0.0294481310993433\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 978, loss 0.029448173940181732\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 979, loss 0.029447359964251518\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 980, loss 0.02944694086909294\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 981, loss 0.029446378350257874\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 982, loss 0.029446575790643692\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 983, loss 0.029446613043546677\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 984, loss 0.029445277526974678\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 985, loss 0.0294457096606493\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 986, loss 0.02944553643465042\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 987, loss 0.02944517508149147\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 988, loss 0.029444800689816475\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 989, loss 0.02944403514266014\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 990, loss 0.02944410964846611\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 991, loss 0.029443740844726562\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 992, loss 0.029443129897117615\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 993, loss 0.02944253385066986\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 994, loss 0.02944115176796913\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 995, loss 0.02944120205938816\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 996, loss 0.029441652819514275\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 997, loss 0.029441658407449722\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "not saving the model\n",
      "epoch 998, loss 0.029441168531775475\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "saving best model\n",
      "epoch 999, loss 0.029440484941005707\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "epoch_loss_list = []\n",
    "accuracy_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "val_min_loss = np.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # get output from the model, given the inputs\n",
    "    outputs = model(inputs_train.float())\n",
    "\n",
    "    # get loss for the predicted output\n",
    "    loss = criterion(outputs, targets_train.float())\n",
    "    print(loss)\n",
    "    # get gradients w.r.t to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # get output from the model, given the inputs\n",
    "    outputs = model(inputs_val.float())\n",
    "\n",
    "    # get loss for the predicted output\n",
    "    loss = criterion(outputs, targets_val.float())\n",
    "        \n",
    "    epoch_loss = loss.item()\n",
    "    \n",
    "    if epoch_loss < val_min_loss:\n",
    "        print(\"saving best model\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, checkpoint_path)\n",
    "        val_min_loss = epoch_loss\n",
    "    else:\n",
    "        print(\"not saving the model\")\n",
    "    \n",
    "    epoch_loss_list.append(epoch_loss)\n",
    " \n",
    "\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "229ce82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE loss is 0.04086948186159134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tf14/lib/python3.7/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([404])) that is different to the input size (torch.Size([404, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "model = linearRegression().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "PATH = checkpoint_path\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "# inferece\n",
    "model.eval()\n",
    "outputs = model(inputs_test.float())\n",
    "loss = criterion(outputs, targets_test.float())\n",
    "print('The MSE loss is {}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "07bb8898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f6fbc27f990>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAsAElEQVR4nO3df5Ac5Xng8e+j1cjMYkcr2escWrSW7MPCYBkp3pPk6BIMPlsyRGbBJiBDUpVKWaW6Ixdzvr2IHGdDjhzK7d3FvjpyOpXNUSmIMAa8FoFYuAr/uMgRkeSVLAmsRBFY0spXyBZLDmlt7Y/n/piZVW9vvzNv9/TM9Mw8nyoVTE/PTvfM7tNvP+/zvq+oKsYYY9rDnEYfgDHGmPqxoG+MMW3Egr4xxrQRC/rGGNNGLOgbY0wbmdvoA4jyjne8Q5csWdLowzDGmKaxf//+n6pqd6X9Mhn0lyxZwr59+xp9GMYY0zRE5Mc++1l6xxhj2ogFfWOMaSMW9I0xpo1Y0DfGmDZiQd8YY9qIV9AXkfUiclREjonIlojnB0TkQPHfYRGZFJGFxee6RORJEfmRiLwsIh9K+ySMMa1raHiEtVtfYOmWZ1m79QWGhkcafUhNrWLJpoh0AA8BHwVOAXtFZKeqvlTaR1UHgcHi/huAu1X1bPHpLwHfVNVPicg8oDPlczDGtKih4RHuefoQY+OTAIyMjnHP04cA6F/Z08hDa1o+Lf1VwDFVPa6qF4DHgZvK7L8R2AEgIr8E/DrwFQBVvaCqo1UdsTGmKSVpsQ/uOjod8EvGxicZ3HW0VofZ8nyCfg9wMvD4VHHbLCLSCawHnipuejdwBvjfIjIsIl8WkUurOF5jTBMqtdhHRsdQLrbYKwX+06NjsbabynyCvkRsc628sgHYHUjtzAV+BfifqroSOAfM6hMAEJFNIrJPRPadOXPG47BmsryfMdmVtMW+qCsfa7upzCfonwIWBx5fDpx27Hs7xdRO4LWnVPXF4uMnKVwEZlHV7arap6p93d0Vp4+YIWkrwhhTH0lb7APrlpHPdczYls91MLBuWWrH1m58gv5e4AoRWVrsiL0d2BneSUTmA9cC3yhtU9X/C5wUkdI39BHgpfBrq2V5P2OyLWmLvX9lDw/espyerjwC9HTlefCW5daJW4WK1TuqOiEidwG7gA7gYVU9IiKbi89vK+56M/C8qp4L/YjfAx4rXjCOA7+T2tEXWd7PmGwbWLdsRhUO+LfY+1f2WJBPkdcsm6r6HPBcaNu20ONHgEciXnsA6Et6gD4WdeUZiQjwlvczJhtKQXtw11FOj46xqCvPwLplFswbIJNTK8dVTSvCGFMf1mLPhpYI+taKMMYYPy0R9MFaEca0i6HhEWvgVaFlgr4xpvXZtAzVs1k2jTFNw8qzq2dB3xjTNKw8u3oW9I0xTcOmZaieBX1jTNOwaRmqZx25xpimYeXZ1bOgb4xpKlaeXR1L7xhjTBuxoG+MMW3Egr4xxrQRC/rGGNNGrCPXGNP22mk+Hwv6xpi21m7z+Vh6xxjT1tptPh+voC8i60XkqIgcE5EtEc8PiMiB4r/DIjIpIguLz70qIoeKz+1L+wSMMaYa7TafT8WgLyIdwEPAx4GrgI0iclVwH1UdVNUVqroCuAf4rqqeDexyXfH5mi6baIwxcbXbfD4+Lf1VwDFVPa6qF4DHgZvK7L8R2JHGwRljTK2123w+Ph25PcDJwONTwOqoHUWkE1gP3BXYrMDzIqLA/1LV7Y7XbgI2AfT29nocljHGlOdTldNu8/n4BH2J2KaOfTcAu0OpnbWqelpE3gl8S0R+pKrfm/UDCxeD7QB9fX2un2+MMV7iVOW003w+PumdU8DiwOPLgdOOfW8nlNpR1dPF/74GfJ1CusgYY2qq3apyfPkE/b3AFSKyVETmUQjsO8M7ich84FrgG4Ftl4rI20r/D3wMOJzGgRtjTDntVpXjq2J6R1UnROQuYBfQATysqkdEZHPx+W3FXW8GnlfVc4GX/zLwdREpvddfqOo30zwBY4yJsqgrz0hEgG/Vqhxfopq99HlfX5/u22cl/caY5MI5fShU5Tx4y/KWzN+LyH6fsnibhsEY05LarSrHlwV9Y0zLaqeqHF82944xxrQRC/rGGNNGLOgbY0wbsaBvjDFtxDpyTdtrp1WTjLGgb9pau62aZIyld0xbs/lZTLuxoG/ams3PYtqNBX3T1tpt1SRjLOibttZuqya1i6HhEdZufYGlW55l7dYXGBoeafQhZYZ15Jq2ZvOzZF/c6irrnC/Pgr5pezY/S3YlCeDlOufte7b0jjEmw5JUV1nnfHkW9I0xmZUkgFvnfHleQV9E1ovIURE5JiJbIp4fEJEDxX+HRWRSRBYGnu8QkWER+cs0D94Y09qSBHDrnC+vYtAXkQ7gIeDjwFXARhG5KriPqg6q6gpVXQHcA3xXVc8Gdvl94OXUjtoY0xaSBPD+lT08eMtyerryCNDTlW/Z1bKS8OnIXQUcU9XjACLyOHAT8JJj/43AjtIDEbkcuBH4Y+DfVHW0xpi2krS6yjrn3XyCfg9wMvD4FLA6akcR6QTWA3cFNn8R+HfA28q9iYhsAjYB9Pb2ehyWMaYdWABPl09OXyK2uVZT3wDsLqV2ROQ3gNdUdX+lN1HV7arap6p93d3dHodljDEmLp+W/ilgceDx5cBpx763E0jtAGuBT4jIDcAlwC+JyKOqemeSgzUmS2xKZtOMfIL+XuAKEVkKjFAI7J8O7yQi84FrgemArqr3UOjYRUQ+DPxbC/jtq5WCpI36NM2qYnpHVSco5Oh3UajAeUJVj4jIZhHZHNj1ZuB5VT1Xm0M1zawUJEdGx1AuBslmnRPFpmQ2zcprGgZVfQ54LrRtW+jxI8AjZX7Gd4DvxDw+0yJabWi8jfo0zcpG5Jq6aLUgaaM+TbOyoG/qotWCpI36NM3Kgr6pi1YLkjbq0zQrm1rZ1EUrzltvg4baW7NWo1nQN3VjQdK0inuHDvHYnhPTo1SbqWTX0jvGGBPD0PDIjIBf0iwlu9bSN8Y0rUakWAZ3HXXOQ9MM1WgW9I1JqFlzuq2iUaOikyzgkiWW3jEmgaHhEQa+dnDGCOOBrx1s2hHGzSjpqOih4RHWbn2BpVueZe3WF2J/Z67ALtAU1WgW9I1J4L6dRxifmnmTPz6l3LfzSIOOqP0kGfCXxnQgUeXHAtyxprcp7vQsvWNMAqNj47G2m2TKpdAWdeUZiQjw5VIsaUwH0uzlxxb0jTGZVClnP7Bu2YznofKAv7SmA2nm8mNL7xiTwILOXKztJr5KOfsko6LTmA6k2j6BRrOWvjEJ3PiBy3h0z4nI7SYdPq3yuC3uJHcHQa2wjoK19I1J4Ns/OhNru4mvFpP0VTtnUiuso9AyLX2rmTb1FNWBWG67ia/aVrlLNfn4NKcIb1TM8mrpi8h6ETkqIsdEZEvE8wMicqD477CITIrIQhG5RET+VkQOisgREbk//VNovVWZTPZ1iMTabuLL4kymad19NDJmVWzpi0gH8BDwUQqLpO8VkZ2q+lJpH1UdBAaL+28A7lbVsyIiwPWq+qaI5IC/FpG/UtU9aZ5Eq63KZLJvUqMH4ru2m2SyViWT1t1HI2OWT3pnFXBMVY8DiMjjwE3AS479NwI7AFRVgTeL23PFf6n/VbTaqkwm+3ocNeI9TTAMv9EakdZI6z3TqtFvZMzyCfo9wMnA41PA6qgdRaQTWE9hIfXStg5gP/BPgYdU9UXHazcBmwB6e3t9jn1akkEaxlSjVvnmVteI6pe03zPp3UfwwjNHJPKusB4xyyenH5WkdLXWNwC7VfXs9I6qk6q6ArgcWCUi7496oapuV9U+Ve3r7u72OKyLWm1VJpN9/St7+OQHe6Zz+B0ifPKD2UpFxFWP+vNGVL9koeImnMOPCvj1ilk+Qf8UsDjw+HLgtGPf2ymmdsJUdRT4DoU7gVRlscPHtLah4RGe2j8y/cc7qcpT+0eatnigXh2LjUhrZCH9G3XhgUJjod4xyye9sxe4QkSWAiMUAvunwzuJyHzgWuDOwLZuYFxVR0UkD/wL4E/SOPCwrHX4mNbWasUDcc8naY68EanYat8zjf4A1wVmSpVXtt4Y62dVq2JLX1UnKOTodwEvA0+o6hER2SwimwO73gw8r6rnAtsuA74tIj+kcPH4lqr+ZXqHb0xjZKH1mKY451PNXUEjUrHVvGdad0C1GGiWlFedvqo+p6rvVdX3qOofF7dtU9VtgX0eUdXbQ6/7oaquVNUPqOr7VfWP0j18YxojS3/EaehyzBkUtb2aHHkjUrHVvGda/QFZ6ne0EbnGJNBq1Tuu4QVR26u9y2lEKjbqPe8dOsSOF08yqUqHCBtXL+aB/uUzYklayyJmaTrmlgj6rTAJkmku/St72PfjszOCRjNX77zhWAcganu1OXJXsPWVRgPv3qFDMybMm1Tl0T0neOXMm/zgxBuRna5BSe7ostLv2BJBv9U61Uz2uap3+t61sCl/5+IE8mrucsoF21d/NlYxkMdt4LkuEDtePDlrX4Dd/3A2cntQM9/RQYvMstlqnWom+7JQ+52m666MHhsTtb2aHHm5YOvTWRrncy/XCZtkuoxWKQdviZa+jcg19dZqDY24U0UnTVX4BlvXnXqczz3NC3NPV57dW653Pu+TcspKv2NLBP1W61Qz2dfohkbaAaReF7E5AlOejeyo956fz0WuQzw/P7vKKOk55XMdXrGk9B2MjI4hXJymICrllKV+x5ZI79iIXFNvA+uWMSc0QckcIZWGRqXpEGoxerbaElTfKRzeMtc/5CjM+lkXJqI7WKO2u4693DWnQ8QrlgS/g6ifGb6jyFI6sCVa+pCdnnHTHvb9+OysFuuUFrZX83vo0yKsReFCNXfLcVqxPx+finVc4Z913vH6qO1R51TJxtWLvWKJa1qFoOAdRZbSgS3R0jem3lwdkq7tvnxahLVYtateA5ii0jCVJG0Rl87JZ7F6EejMzeGxPSdm3V1E3cX4BOvgnUaWBvO1TEvfmHpKaxGVcM266/XBICMSPWiq2kW7kt4tx2nFJj3G0s9a0Jnj9fOzc/rlAnulu4s71/Ty1P4RzkfcqQCRdzGX5OYwVubnhu+SstTvaEHfmARcATrOcolRNesuwRZhnNGzcdRjErWogO2j9LO+sOFqBp48yPjkxZPNdQhf2HB15Ot80jB/8eKJWam64N1F1F1MuD8nqCfis7MRucZ4ykqZW9iady+IHMiz5t0LvH+GbyqoHi3CaqpLolqxuQ7h3C8mWLrl2RnfW7m7GZfg+ccNnj5pGFc1Ubl0mes1As7Szqz0O1rQN5mVpTK3sFd/Fh0QXNujlAt+PV15Z1DrcpQtdiXIl5dU0zkcDsRdnTne/PnE9DEGvzffgF/u/H2CZ6mxUKsVi10Xr+DdTVYbLBb0TWZleXqNNKoxyqWIyg0Euu8TVzPwtYOMB5qbuTnCfZ+ITnH4SGsStaHhET73xMFZ51X63lxrCwdVGghV4gqq4cZCJbk5MLejw3v/fK6DT36wh6f2jzhz9FlusFj1jsmsLJW5haVRjbFx9eJY20v6V/YweOs1MyptBm+9ZkYwibv0YRrnUwp05TqjK6WpBPeUEFHvFRyrcPdXD7Bky7N87omDsco033pJbrpyqdKxlaqa+t61cMaYgwWduRnVTlmqyw+zoG8yK0tlbmFL3h59DK7tUR7oX86da3pnrLN755reWDNORhkaHmHgyYMzAuLAkwfLBv6BdcvIdczsncx1iHdfwr1Dh/jsVw+UDbaLuvJ8bd8J5/NQGOTks+xkVFAtXWri9hmMnh+nf2UPu7dc7wz8PV15Xtl64/QdyD1PH5qRYgtXCGW5weKV3hGR9cCXgA7gy6q6NfT8AHBH4Ge+D+gGLgX+HPgnwBSwXVW/lM6hm1aXpTK3sO8fj56N0bXd5YH+5bGDfKXUwf3PHJlR3QIwPqnc/8yRsqmFyVDvZPixK50SrkKKUvrePvvVAxXPb2x8kvufOeLMhw8Nj1Q1JiEs2Ijw+Z1zteI/98RB7v7qARZ15elylJZmocFSMeiLSAfwEPBRCouk7xWRnar6UmkfVR0EBov7bwDuVtWzIvIW4HOq+gMReRuwX0S+FXytaS717JzKUplbWK3KJqOEP/PzFybK9nW4yiLLlUve/8yRyBHGpQtFuQtNpSqk0tQG/St7vIJ+6VhLxxtVN5+WcEAP/s6VLiylgL7vx2d5oH+5s7VeusMYGR1zplB8Ule15tPSXwUcU9XjACLyOHAT4ArcG4EdAKr6E+Anxf//fyLyMtBT5rUmw6rtnEpywchKmVujRH3mLtWkDipdKMrlqMulU/K5Dh68pXAns3brC4mPr1zdfBICzt/B0gI5UfP+f/0HI85J34Jcw7Zcs5bWk0/Q7wGCl/JTwOqoHUWkE1hPYSH18HNLgJXAi7GP0kO1q/GYyqqppslyNUOW+QwuKimlDmpR0um62JweHStbe18K+HHnwHG9l++NVHimzLBXtt4443G4QeK6gJ67MEmuY4rcHJlRPeUr/HMbUdbp05EbNfbMdbYbgN2qOiOxKSJvBZ4CPquq/xj5JiKbRGSfiOw7cybe1bCUUwyuYvTonhPcO5TebaCprnOqUdUMcatYfLkG3lY7FUKYb+s9mKa47xNXR84AmrSkc2h4JDIIQCEQzJsb/eyda3oLlUYxLlzlLCpWK1VSqrAp1ykbFFUJVC6cj08qb71kbsVqnyjBheZrMVuqD5+gfwoI1pBdDpx27Hs7xdROiYjkKAT8x1T1adebqOp2Ve1T1b7u7nh5r8ccnUiu7SaZaqppGlHNUMs/qnrl9F2fbT43Z0bVT3h93vB0EHGmhwirNMhpbHyKOTB9oQlXIaXxHZcuauWOIzdHWNCZ4/ToGIO7jnLdld3kcx2RPycoyUVp9Pw4u7dcH/tzff38+HRjtFENIZ+gvxe4QkSWisg8CoF9Z3gnEZkPXAt8I7BNgK8AL6vqf0vnkGdz/SLUajReuxpYt8zrjyhKI8ovs1wr7SvqM8/NESamdNb6vKWL2eCuo7NSD+NTyueeKF+26eI1lQFw2fw8r269kX948IYZqdVqv2PvGT+lEFRLF/hH95xgYnKSBZ25sjOHJrkozRFh6ZZnEy27+NieE2Vn6qx1WWfFoK+qExRy9LuAl4EnVPWIiGwWkc2BXW8GnlfVc4Fta4HfAq4XkQPFfzekePymjqqZfreaC4ZLpdRNlmulfUV95m+9ZO6skszgxaxcdUmSOx3foO1634F1y7zSMmG5OcIXb1vB7i3Xe/2OhT8TgPEpePPnE/xpxM8p/f4kaRxOqiZuVCqFC3OXY2ZQ1/a0eNXpq+pzwHOhbdtCjx8BHglt+2ui+wRMk0paTZN2+aVPx3CjlzRMS/gzX7rl2cj9SkHXdd4w8+IQ/C7K8V2MxPVzStUwj+05EStQvvWSudPloqVjTWJ8SmcVG5QGsEVdKFyEQgs/Ses+7PTomHNtgVqU/QbZiFxTN6VRj6WRjdVUKfikblw10Vmola5GpVRZ1F1VUOkCGezrcJnXIbPuNhZ05shFzC18/sKE8y7igf7l/OltK5zvE2X0/PisfpmkwheMqAFs5ZRG5KYR8KHwXb3hKPt0bU+LBX3TlHxSN66a6CzUSpdTKW1VaX3eUpB2dTJ2iHh3XGoxyAUv2MOf/xiDt14zqwT09fPjZdNH/St7YpWNLurKe3eyCuVTCuELZZx5/YPTUVTTIV5SSms2apqRlgj6l86LbtW4tpvm5/MHU8ucvutPv9qQ4FNx9LV9sxf9mFJmzGvTv7KH//qb10T2o8RprYYXhypdkD771QORYwEqdZSPT/qtkVsKjL7flQJ3rOmNfG4OhbuQpGW7E4E7gjifXalP4ou3rYjsB6tFP5ePlgj66vgiXNtN8/NJ3dSyJeUKMK7tvnzSVlGLt0Rtd3W8J6kvh5kXpHJGRsecgfXcBXervdSKDgZG3+9qjkDfuxbyxdtWzFg6MTenUFkUrOq55+lD5GJEPgX+/dcPTR9bOR0is2Y+daU1qymMqEZLBP3zjrUqXdtN8/NJ3dSyJfVA/3LWvmfhjG1r37Ow6lHgad+dRAWcSjl/lzj17EmqhCZVp7+fUuDzPdYpvTgnz/DnP8arW2/ki7etmHWnAoWLaNzQULpYVTqejasXz5iNs9LAwNL3U+rvuPurB1IdRBjFFlExTcknONZywrah4RF+cOKNGdt+cOINhoZHqvr59ag4ivpcfGatjDOzpWt6DqH8+JmoGTY/+cEevv2jMxWnYQi/5/3PHPE+Xh8r/+h5Rs+P09WZ4+fjk5HH8uieE3z7R2e47sruGYuslJt2pN5TlLRE0K/FXCMm23yDY60mbKvVql4D65ZFrooVvDtZ+56FkSme8J1HOeHPZYmjDLSkNBVDnIRp1IXZ5/XhGTaf2j8ynfaodJyni6mlwV1HEy/CXu64gv91KQ0MC3P9ftR7hbiWSO/c94mrZ5WQVbt8nElfmvPgNLocs6YDv8K9waHHj33mQ5Gppcc+86Hq39shyXqzad2dBPs0IipFZ8jn5nj1OzRK1O9HvQcRtkRLP8vzrpuCtG9hG12Omc/NiewzysfpIYwwuOto5AIo4VZfGgF+aHiE+5854tUijhuA0q5CGRkdY+3WF2ZVLYVlvR8v6kJY70GELRH0weZdz7q0b2EbPcXC2ER0cHFt91Wv84o7ItU3719unvpq1av1HjeN5ct1Iaz3CnEtE/QbMS+18ef6g036h9zoKRZqNctmvc4r6o4iSmksks9UDD1d+emqFZcr3nkpf//aubL7NFotAn5w9bCwemcqWiLo2wId7ee6K7sjO8vqldN3LRxS7YjNerX6vOfpn1tIV4WXEQy3hn2P8advXij7fBqt7Fq11KsxpVo2FtUzU9ESHbmtMIWuiafROf01714Qa7uveg3Y8b1zCObISzXlr269kTvW9Jadz9+lXP9BWgH/V9+zMPEAtFrJ0iR/LdHSb3R+19Rfo7/z4ROjsbbH4Wr1pZnCHFi3zCunH3XnMjQ8wlP7R2bN59/3roVVXZzSaJ0r8Levvs6l87IT2uoxtUIcLdHSb9TERcbfvI7otIdreyWN/s7rPQo87VXA+lf2MPipa2ZMWRAlKoVVzZ11Nckv39eOT2rFhcvrRcD7LqheWiLoN7pm21TW6Wh5ubZX0qjJqhqlFinM/pU901MWlJuRM6yaTvlqWvPV3gmkMUNmXMrslGOt1m32lZ17oCr85cGfOLdXOxeKKc835ZD23OGNHpvhyj/XKqzETWfFTQW5Zo90dVYn7cTucVQndeVz/GJiKpUF1F1+KT+XN38+MWspySQEuCTX4XW8I6NjLN3yLIu68rGmZ6gVr5a+iKwXkaMickxEtkQ8PxBYDvGwiEyKyMLicw+LyGsicjjtgy9x3cpl5RavVcVJObhWCXJt95HmoixxXeIYhOXaXq046awkqaA4Lf04F4iwqDs0ofC3+pa55T+7SqmoSl4/Pw5ysQy1GgqxZiwtfQ+P7TnR8KKTir+hItIBPAR8HLgK2CgiVwX3UdVBVV2hqiuAe4DvqmppcpBHgPVpHrTJhjgpB9cfWgPuuFMx5sjdu7ZXa2DdMnKh/o/g4h5BSVJBcQK5K9D5BMBgdRLMvGMaHRsve6d04wcuq/pOanxSU1mOMGl1kOut61l04tMsWQUcU9XjqnoBeBy4qcz+G4EdpQeq+j0gegJw09TipBxGHaV6ru21lEZONU7LODXhiOGIIEkqm1yTE0ZtT7M/xfOUgEK6Ngv19/lcB9dd2Z3qHD/1LDrxyen3ACcDj08Bq6N2FJFOCq36u+IeiIhsAjYB9PbGW4jCZtlsjDijRxs9grYkrYF81aQ4fI4xnI8f3HV0Vi46asFvSPZZu3LTUdur6U8ZGh6ZNYuor7TSta54UUlpioklb89HDgwMc/V9JB3Ylhafln5U08X1jW0AdgdSO95Udbuq9qlqX3d3vKobm2WzMeK0+LJSbZP1gXyufLyrRRnVek/yWf/CMWeQa3vS/pT7dh6pqiM1zn2Ua7nU37jmMuc01K6f3yHCK1tv5Loru50rlwXlcx1sXL048nu4Y01v3VfLCvJp6Z8CFgceXw6cdux7O4HUTr00upKjXcX53LPyHTV6UFclrouSq9UY1XrPymcdpVILO5/rYHJqigsRg8Y6HTObukw57rrKjdp2XY5Kn/2OF0869rioNEL5gf7l9L1rYea+B5+gvxe4QkSWAiMUAvunwzuJyHzgWuDOVI/Qk82y2RhxPvcsfEdZSTO5uC4+paUEfefkycJnDbNTVZW8Ze4cxifhwuTstFLcgW+uTvUkF/hSx61P+i48QjkL30NQxfSOqk5QyNHvAl4GnlDVIyKyWUQ2B3a9GXheVWdMoSciO4C/AZaJyCkR+d30Dt+YeNJKM7kW86i0yEclrsAYXNS8FmkB12FXczpRqapKRsfGyy6enoZFXXnn57ygM1f298O3o35sfJLPPXGwYQOwyvEanKWqzwHPhbZtCz1+hEJ5Zvi1G5MfnjHpSiv14UpLVzvup9wsm7VsNboOu5rTibOQej29fu4XrOztirwI3fiBy3jx+M9mTP98+YJLpj/3jasXe3XiwsW7gqzN+tsSI3KNiSOLt9wlWc7Hx5WVfpKw8+NTfN/RGfu1fadmdV7//WvnuOIPn2Xw1hU80L+cV8686dWZG1TLNW/jsqBvTMZk+aIUh+9qW1G68jkufcvcWK8X8V/ExrWbq1ppfIrp1vpjn/nQjL6Krs6c1/QOWbkItsSEa8aY6rjW9q1mzd+o/hO/Y+ngN665bPqxTxb9zjW9/Olvrkj0fr6Cpb3BktXhz3+MwVuvme5vceX9s1IsYC19YxJwTRyWtcU7fMWt0/cRlao6e+4XkVU1pTAZNSmZcnFAU1c+x4WJyelKngWdOb6w4eoZd0al9yu9Nk2u1nrw7iw8AJDi8ZcWd290us6CvjEJ1Hsx61qrVcd0OFUVNSI3N0cYvPWa6f3Wbn1hVgew4rcGb/D97h065N3p6suntV5uacksdOpaeseYBOq1rGGr6V/Zw22rFs9YavG2VYtnfG5xRh+X4xqE1SHiHJFbTpyLein909OVn3W30egR4NbSNyahVulwradKSy0ODY841yqImxN3XSSmVHnsMx/i3qFD7HjxZNkBVz1d+aqqqLI4AtyCvjGmbn0U5eY+6l/Zw+Cuo87FaeKmzuY7JlYrreHwQP9yHuhfztqtLzjPvVI6qZIsjgC39I4xpm5LjlZq+bqeV+LnwH3XcKjlZIBZmWgwyIK+McaZ/y43OVkSlVYAKzcNRVy+azjUsn8mi30/lt4xxlS12Hkclaqe0qyKipNaids/E2cN4qz1/VhL3xhTt5XAKrV802wZ1yq1kmQN4iyxlr4xpqYrgYVVavmm1TKu1TxGlTqjs86CvjGm5UYYl9QitZLFMsw4LOgbY1puhHFJnNy772uyWIYZh+X0jTGZrDKpVpLcu89rsliGGYdXS19E1gNfAjqAL6vq1tDzA8AdgZ/5PqBbVc9Weq0xJr4kLdhK0kyF1OL44kqSe/d5TbOveVAx6ItIB/AQ8FEKi6TvFZGdqvpSaR9VHQQGi/tvAO4uBvyKrzXGxBOexTELk3gFZeX4kuTefV+TtTLMOHzSO6uAY6p6XFUvAI8DN5XZfyOwI+FrTQsbGh5h7dYXMrluaDMp1xrNgqwcX1dnLtZ2qDx4rBX4BP0e4GTg8anitllEpBNYDzyV4LWbRGSfiOw7cybdUYCm8Zq9tjlLsl494jqOkdGxul7wXdWm5apQa5mvz0qjxyfoR43OcH1sG4DdqlpaQNL7taq6XVX7VLWvuzvd+T5M42Wl9dcKst4aLXcc9bzgvxEx2Vq57VC7Du0sNXp8gv4pYHHg8eXAace+t3MxtRP3taaFZb112kyyXj3is0xiPS74SS+OwaUQd2+5PpXcfZYaPT5Bfy9whYgsFZF5FAL7zvBOIjIfuBb4RtzXmtaX9dZpM8l6eWX4+FxqfcHP0sUxS42eitU7qjohIncBuyiUXT6sqkdEZHPx+W3FXW8GnlfVc5Vem/ZJmOxr1cE/jVKL6pE0yyyDx+ear77WF/wslVZmaUCXaA3m1qhWX1+f7tu3r9GHYVKWhdptEy1qMe98riPVfHbSn90Kvze1/HxLRGS/qvZV2s+mYTB108y1za2ulpOIxW1xB4P8/HyOcxcmGJ8sNE6zNibBV5buOizoG2NqnnP2veCHW8RRyx0204yWQVlp9NjcO8aYzHS0R91xRLGqr+Qs6BtjMlPp4hvMreorOQv6xpjMlIH6BHOr+qqOBX1jTGZE3XHk5ggLOnOZHJPQjKwj1xiTmZkxs1Tl0qos6BtjMrXua1aqXFqVpXeMMZmaJsDUlgV9Y0xmSjZN7VnQN8ZkpmTT1J7l9I0xde1AbYW5dJqZBX1jDFCfDtSsVAm1M0vvGGPqJkuLibQrC/rGmLqxKqHGs6BvjKkbqxJqPK+gLyLrReSoiBwTkS2OfT4sIgdE5IiIfDew/fdF5HBx+2dTOm5jTBOyKqHGq9iRKyIdwEPARyksdL5XRHaq6kuBfbqAPwPWq+oJEXlncfv7gc8Aq4ALwDdF5FlV/fvUz8QYk3k2zULj+VTvrAKOqepxABF5HLgJeCmwz6eBp1X1BICqvlbc/j5gj6qeL772uxTW0v3P6Ry+MabZ2DQLjeWT3ukBTgYenypuC3ovsEBEviMi+0Xkt4vbDwO/LiJvF5FO4AZgcbUHbYwxJhmflr5EbAuvpj4X+CDwESAP/I2I7FHVl0XkT4BvAW8CB4GJyDcR2QRsAujt7fU7emOMMbH4BP1TzGydXw6cjtjnp6p6DjgnIt8DrgH+TlW/AnwFQET+U3HfWVR1O7AdoK+vL3xRMcaYTGj2EcU+6Z29wBUislRE5gG3AztD+3wD+DURmVtM46wGXgYIdOr2ArcAO9I6eGOMqafSiOKR0TGUiyOKh4ZHGn1o3iq29FV1QkTuAnYBHcDDqnpERDYXn99WTON8E/ghMAV8WVUPF3/EUyLydmAc+Feq+npNzsQYY2osS+sOJOU1946qPgc8F9q2LfR4EBiMeO2vVXOAxhiTFa0wothG5BpjjKdWGFFsQd8YYzy1wohim1rZGGM8tcKIYgv6xhgTQ7OPKLb0jjHGtBEL+sYY00Ys6BtjTBuxoG+MMW3EOnKNMTXR7HPUtCoL+saY1JXmqClNWVCaowawwB9S74ujpXeMMakrN0eNuagRE7hZ0DfGpK4V5qiph0ZcHC29Y4ypWjhF0dWZ4/Xz47P2a6Y5auqhERdHa+kbY6oSlaJ48+cT5DpmLrrXbHPU1EMjJnCzoG+MqUpUimJ8Srl03lx6uvII0NOV58FbllsnbkgjJnCz9I4xpiquVMQbY+Mc+MLH6nw0zaURE7hZ0DfGVGVRV56RiMBv+Xs/9Z7AzSu9IyLrReSoiBwTkS2OfT4sIgdE5IiIfDew/e7itsMiskNELknr4I0xjdcKc8y3k4pBX0Q6gIeAjwNXARtF5KrQPl3AnwGfUNWrgVuL23uAfw30qer7Kayxe3uaJ2CMaaz+lT08eMtyy983CZ/0zirgmKoeBxCRx4GbgJcC+3waeFpVTwCo6muh98iLyDjQCZxO48CNMdnR7HPMtxOf9E4PcDLw+FRxW9B7gQUi8h0R2S8ivw2gqiPAfwFOAD8B3lDV56PeREQ2icg+Edl35syZuOdhjDHGg0/Ql4htGno8F/ggcCOwDvgPIvJeEVlA4a5gKbAIuFRE7ox6E1Xdrqp9qtrX3d3tfQLGGGP8+aR3TgGLA48vZ3aK5hTwU1U9B5wTke8B1xSfe0VVzwCIyNPArwKPVnXUxhhjEvFp6e8FrhCRpSIyj0JH7M7QPt8Afk1E5opIJ7AaeJlCWmeNiHSKiAAfKW43xhjTABVb+qo6ISJ3AbsoVN88rKpHRGRz8fltqvqyiHwT+CEwBXxZVQ8DiMiTwA+ACWAY2F6bUzHGGFOJqIbT840nImeAHyd8+TuAn6Z4OM2kXc+9Xc8b7Nzt3C96l6pW7BDNZNCvhojsU9W+Rh9HI7TrubfreYOdu517fDbhmjHGtBEL+sYY00ZaMei3c0dxu557u5432Lm3q8Tn3nI5fWOMMW6t2NI3xhjjYEHfGGPaSFMG/Urz+0vBfy8+/0MR+ZVGHGcteJz7HcVz/qGIfF9Eron6Oc3IZ12H4n7/TEQmReRT9Ty+WqpmTYtm5/E7P19EnhGRg8Vz/51GHGfaRORhEXlNRA47nk8W51S1qf5RGBX8D8C7gXnAQeCq0D43AH9FYbK4NcCLjT7uOp77rwILiv//8XY698B+LwDPAZ9q9HHX8XvvojDdeW/x8Tsbfdx1PPc/BP6k+P/dwFlgXqOPPYVz/3XgV4DDjucTxblmbOlPz++vqheA0vz+QTcBf64Fe4AuEbms3gdaAxXPXVW/r6qvFx/uoTBBXivw+d4Bfg94Cngt4rlm5XPu5da0aGY+567A24rze72VQtCfqO9hpk9Vv0fhXFwSxblmDPo+8/v77NOM4p7X71JoCbSCiudeXKntZmBbHY+rHhKvadECfM79fwDvozD77yHg91V1qj6H11CJ4lwzLozuM7+/zz7NyPu8ROQ6CkH/n9f0iOrH59y/CPyBqk4WGn0tI86aFh8B8sDfiMgeVf27Wh9cjfmc+zrgAHA98B7gWyLyf1T1H2t8bI2WKM41Y9D3nd+/0j7NyOu8ROQDwJeBj6vqz+p0bLXmc+59wOPFgP8O4AYRmVDVobocYe1Us6ZFswd9n3P/HWCrFhLdx0TkFeBK4G/rc4gNkyjONWN6x2d+/53Abxd7t9dQWKbxJ/U+0BqoeO4i0gs8DfxWC7Tygiqeu6ouVdUlqroEeBL4ly0Q8KG6NS2anc+5n6Bwh4OI/DKwDDhe16NsjERxrula+uoxvz+Fyo0bgGPAeQotgabnee6fB94O/FmxxTuhLTAToee5tySfc9cya1o0M8/v/T8Cj4jIIQopjz9Q1aafcllEdgAfBt4hIqeALwA5qC7O2TQMxhjTRpoxvWOMMSYhC/rGGNNGLOgbY0wbsaBvjDFtxIK+Mca0EQv6xhjTRizoG2NMG/n/Y1RWtB457zsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(targets_test.cpu().detach().numpy(), outputs.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "345258b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7116],\n",
       "        [0.7114],\n",
       "        [0.7202],\n",
       "        [0.7189],\n",
       "        [0.7144],\n",
       "        [0.7140],\n",
       "        [0.7075],\n",
       "        [0.7334],\n",
       "        [0.7150],\n",
       "        [0.7135],\n",
       "        [0.7092],\n",
       "        [0.7133],\n",
       "        [0.7119],\n",
       "        [0.7068],\n",
       "        [0.6989],\n",
       "        [0.7264],\n",
       "        [0.7120],\n",
       "        [0.7277],\n",
       "        [0.7108],\n",
       "        [0.7101],\n",
       "        [0.7126],\n",
       "        [0.7168],\n",
       "        [0.7102],\n",
       "        [0.7170],\n",
       "        [0.7160],\n",
       "        [0.7185],\n",
       "        [0.7202],\n",
       "        [0.7180],\n",
       "        [0.7178],\n",
       "        [0.7090],\n",
       "        [0.7157],\n",
       "        [0.7247],\n",
       "        [0.7120],\n",
       "        [0.7172],\n",
       "        [0.7317],\n",
       "        [0.7076],\n",
       "        [0.7091],\n",
       "        [0.7157],\n",
       "        [0.7157],\n",
       "        [0.7246],\n",
       "        [0.7142],\n",
       "        [0.7267],\n",
       "        [0.7185],\n",
       "        [0.7119],\n",
       "        [0.7249],\n",
       "        [0.7180],\n",
       "        [0.7191],\n",
       "        [0.7218],\n",
       "        [0.7132],\n",
       "        [0.7036],\n",
       "        [0.7147],\n",
       "        [0.7416],\n",
       "        [0.7147],\n",
       "        [0.7169],\n",
       "        [0.7143],\n",
       "        [0.7244],\n",
       "        [0.7176],\n",
       "        [0.7235],\n",
       "        [0.7174],\n",
       "        [0.7188],\n",
       "        [0.7051],\n",
       "        [0.7131],\n",
       "        [0.7422],\n",
       "        [0.7241],\n",
       "        [0.7075],\n",
       "        [0.7111],\n",
       "        [0.7136],\n",
       "        [0.7210],\n",
       "        [0.7097],\n",
       "        [0.7208],\n",
       "        [0.7204],\n",
       "        [0.7180],\n",
       "        [0.7087],\n",
       "        [0.7209],\n",
       "        [0.7143],\n",
       "        [0.7086],\n",
       "        [0.7104],\n",
       "        [0.7234],\n",
       "        [0.7133],\n",
       "        [0.7379],\n",
       "        [0.7242],\n",
       "        [0.7587],\n",
       "        [0.7348],\n",
       "        [0.7079],\n",
       "        [0.7203],\n",
       "        [0.7102],\n",
       "        [0.7294],\n",
       "        [0.7144],\n",
       "        [0.7263],\n",
       "        [0.7092],\n",
       "        [0.7341],\n",
       "        [0.7130],\n",
       "        [0.7260],\n",
       "        [0.7162],\n",
       "        [0.7231],\n",
       "        [0.7210],\n",
       "        [0.7178],\n",
       "        [0.7142],\n",
       "        [0.7093],\n",
       "        [0.7104],\n",
       "        [0.7113],\n",
       "        [0.7185],\n",
       "        [0.7124],\n",
       "        [0.7266],\n",
       "        [0.7196],\n",
       "        [0.7155],\n",
       "        [0.7120],\n",
       "        [0.7146],\n",
       "        [0.7215],\n",
       "        [0.7067],\n",
       "        [0.7090],\n",
       "        [0.7148],\n",
       "        [0.7091],\n",
       "        [0.7164],\n",
       "        [0.7234],\n",
       "        [0.7185],\n",
       "        [0.7135],\n",
       "        [0.7593],\n",
       "        [0.7076],\n",
       "        [0.7177],\n",
       "        [0.7186],\n",
       "        [0.7197],\n",
       "        [0.7106],\n",
       "        [0.7129],\n",
       "        [0.7101],\n",
       "        [0.7105],\n",
       "        [0.7147],\n",
       "        [0.7204],\n",
       "        [0.7207],\n",
       "        [0.7193],\n",
       "        [0.7179],\n",
       "        [0.7257],\n",
       "        [0.7128],\n",
       "        [0.7143],\n",
       "        [0.6994],\n",
       "        [0.7052],\n",
       "        [0.7129],\n",
       "        [0.7079],\n",
       "        [0.7192],\n",
       "        [0.7137],\n",
       "        [0.7180],\n",
       "        [0.7238],\n",
       "        [0.7155],\n",
       "        [0.7207],\n",
       "        [0.7149],\n",
       "        [0.7168],\n",
       "        [0.7076],\n",
       "        [0.7230],\n",
       "        [0.7097],\n",
       "        [0.7099],\n",
       "        [0.7135],\n",
       "        [0.7158],\n",
       "        [0.6965],\n",
       "        [0.7189],\n",
       "        [0.7053],\n",
       "        [0.6882],\n",
       "        [0.7123],\n",
       "        [0.7185],\n",
       "        [0.7090],\n",
       "        [0.7070],\n",
       "        [0.7155],\n",
       "        [0.7159],\n",
       "        [0.7140],\n",
       "        [0.7163],\n",
       "        [0.7066],\n",
       "        [0.7267],\n",
       "        [0.7121],\n",
       "        [0.7335],\n",
       "        [0.7167],\n",
       "        [0.7200],\n",
       "        [0.7294],\n",
       "        [0.7206],\n",
       "        [0.7441],\n",
       "        [0.7081],\n",
       "        [0.7236],\n",
       "        [0.7175],\n",
       "        [0.7161],\n",
       "        [0.7112],\n",
       "        [0.7147],\n",
       "        [0.7180],\n",
       "        [0.7153],\n",
       "        [0.7206],\n",
       "        [0.7117],\n",
       "        [0.7241],\n",
       "        [0.7199],\n",
       "        [0.7132],\n",
       "        [0.7162],\n",
       "        [0.7104],\n",
       "        [0.7259],\n",
       "        [0.7001],\n",
       "        [0.7134],\n",
       "        [0.7109],\n",
       "        [0.7196],\n",
       "        [0.7120],\n",
       "        [0.7158],\n",
       "        [0.7139],\n",
       "        [0.7074],\n",
       "        [0.7171],\n",
       "        [0.7162],\n",
       "        [0.7123],\n",
       "        [0.7123],\n",
       "        [0.7043],\n",
       "        [0.7155],\n",
       "        [0.7118],\n",
       "        [0.7137],\n",
       "        [0.7139],\n",
       "        [0.7174],\n",
       "        [0.7170],\n",
       "        [0.7188],\n",
       "        [0.7116],\n",
       "        [0.7064],\n",
       "        [0.7109],\n",
       "        [0.6998],\n",
       "        [0.7192],\n",
       "        [0.7051],\n",
       "        [0.7229],\n",
       "        [0.7204],\n",
       "        [0.7244],\n",
       "        [0.7089],\n",
       "        [0.7083],\n",
       "        [0.6975],\n",
       "        [0.7067],\n",
       "        [0.7228],\n",
       "        [0.7204],\n",
       "        [0.6988],\n",
       "        [0.7251],\n",
       "        [0.7101],\n",
       "        [0.7131],\n",
       "        [0.7142],\n",
       "        [0.7275],\n",
       "        [0.7080],\n",
       "        [0.7056],\n",
       "        [0.7130],\n",
       "        [0.7309],\n",
       "        [0.7304],\n",
       "        [0.7151],\n",
       "        [0.7148],\n",
       "        [0.7188],\n",
       "        [0.7156],\n",
       "        [0.7024],\n",
       "        [0.7146],\n",
       "        [0.7150],\n",
       "        [0.7135],\n",
       "        [0.6829],\n",
       "        [0.7196],\n",
       "        [0.7189],\n",
       "        [0.7098],\n",
       "        [0.7156],\n",
       "        [0.7078],\n",
       "        [0.7184],\n",
       "        [0.7149],\n",
       "        [0.7257],\n",
       "        [0.7068],\n",
       "        [0.7029],\n",
       "        [0.6971],\n",
       "        [0.7105],\n",
       "        [0.7062],\n",
       "        [0.7216],\n",
       "        [0.7075],\n",
       "        [0.7315],\n",
       "        [0.7192],\n",
       "        [0.7130],\n",
       "        [0.7278],\n",
       "        [0.7257],\n",
       "        [0.7089],\n",
       "        [0.7110],\n",
       "        [0.7084],\n",
       "        [0.7226],\n",
       "        [0.7172],\n",
       "        [0.7151],\n",
       "        [0.7112],\n",
       "        [0.7184],\n",
       "        [0.7198],\n",
       "        [0.7090],\n",
       "        [0.7181],\n",
       "        [0.7118],\n",
       "        [0.7333],\n",
       "        [0.7152],\n",
       "        [0.7250],\n",
       "        [0.7082],\n",
       "        [0.7102],\n",
       "        [0.7189],\n",
       "        [0.7194],\n",
       "        [0.7135],\n",
       "        [0.7251],\n",
       "        [0.7064],\n",
       "        [0.7196],\n",
       "        [0.7007],\n",
       "        [0.7186],\n",
       "        [0.7120],\n",
       "        [0.7110],\n",
       "        [0.7098],\n",
       "        [0.7164],\n",
       "        [0.7165],\n",
       "        [0.7199],\n",
       "        [0.6819],\n",
       "        [0.7193],\n",
       "        [0.7082],\n",
       "        [0.7376],\n",
       "        [0.7072],\n",
       "        [0.7077],\n",
       "        [0.7158],\n",
       "        [0.7149],\n",
       "        [0.7244],\n",
       "        [0.7042],\n",
       "        [0.7223],\n",
       "        [0.7230],\n",
       "        [0.7045],\n",
       "        [0.7188],\n",
       "        [0.7235],\n",
       "        [0.7061],\n",
       "        [0.7245],\n",
       "        [0.7209],\n",
       "        [0.7089],\n",
       "        [0.7090],\n",
       "        [0.7154],\n",
       "        [0.7009],\n",
       "        [0.7227],\n",
       "        [0.7212],\n",
       "        [0.7198],\n",
       "        [0.7196],\n",
       "        [0.7261],\n",
       "        [0.6944],\n",
       "        [0.7133],\n",
       "        [0.7178],\n",
       "        [0.7487],\n",
       "        [0.7073],\n",
       "        [0.7217],\n",
       "        [0.7102],\n",
       "        [0.7203],\n",
       "        [0.7235],\n",
       "        [0.7060],\n",
       "        [0.7179],\n",
       "        [0.7157],\n",
       "        [0.7095],\n",
       "        [0.7177],\n",
       "        [0.7214],\n",
       "        [0.7129],\n",
       "        [0.7165],\n",
       "        [0.7560],\n",
       "        [0.7151],\n",
       "        [0.6834],\n",
       "        [0.7240],\n",
       "        [0.7289],\n",
       "        [0.7105],\n",
       "        [0.6999],\n",
       "        [0.7220],\n",
       "        [0.7259],\n",
       "        [0.7144],\n",
       "        [0.7223],\n",
       "        [0.7118],\n",
       "        [0.7242],\n",
       "        [0.7114],\n",
       "        [0.7203],\n",
       "        [0.7305],\n",
       "        [0.7107],\n",
       "        [0.7089],\n",
       "        [0.7174],\n",
       "        [0.7167],\n",
       "        [0.7285],\n",
       "        [0.7209],\n",
       "        [0.7072],\n",
       "        [0.7118],\n",
       "        [0.7116],\n",
       "        [0.7201],\n",
       "        [0.7205],\n",
       "        [0.7212],\n",
       "        [0.7069],\n",
       "        [0.7156],\n",
       "        [0.7601],\n",
       "        [0.7202],\n",
       "        [0.7184],\n",
       "        [0.7070],\n",
       "        [0.7077],\n",
       "        [0.7171],\n",
       "        [0.7209],\n",
       "        [0.7132],\n",
       "        [0.7156],\n",
       "        [0.7129],\n",
       "        [0.7136],\n",
       "        [0.7512],\n",
       "        [0.7212],\n",
       "        [0.7217],\n",
       "        [0.7260],\n",
       "        [0.6924],\n",
       "        [0.7131],\n",
       "        [0.7109],\n",
       "        [0.7183],\n",
       "        [0.7171],\n",
       "        [0.7117],\n",
       "        [0.7150],\n",
       "        [0.7352],\n",
       "        [0.7287],\n",
       "        [0.7160],\n",
       "        [0.7089],\n",
       "        [0.7211],\n",
       "        [0.7324],\n",
       "        [0.7125],\n",
       "        [0.7190],\n",
       "        [0.7181],\n",
       "        [0.7138],\n",
       "        [0.7112],\n",
       "        [0.7145],\n",
       "        [0.7185]], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f67644eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "ed347ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6fa0fec390>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2,3, figsize=[15,15])\n",
    "axs[0,0].scatter(features_scaled_train[:,0], target_accuracy_train,\n",
    "                label=f\"rho={stats.spearmanr(features_scaled_train[:,0], target_accuracy_train)[0]}\")\n",
    "axs[0,0].legend()\n",
    "axs[0,1].scatter(features_scaled_train[:,1], target_accuracy_train,\n",
    "                label=f\"rho={stats.spearmanr(features_scaled_train[:,1], target_accuracy_train)[0]}\")\n",
    "axs[0,1].legend()\n",
    "axs[0,2].scatter(features_scaled_train[:,2], target_accuracy_train,\n",
    "                label=f\"rho={stats.spearmanr(features_scaled_train[:,2], target_accuracy_train)[0]}\")\n",
    "axs[0,2].legend()\n",
    "axs[1,0].scatter(features_scaled_train[:,3], target_accuracy_train,\n",
    "                label=f\"rho={stats.spearmanr(features_scaled_train[:,3], target_accuracy_train)[0]}\")\n",
    "axs[1,0].legend()\n",
    "axs[1,1].scatter(features_scaled_train[:,4], target_accuracy_train,\n",
    "                label=f\"rho={stats.spearmanr(features_scaled_train[:,4], target_accuracy_train)[0]}\")\n",
    "axs[1,1].legend()\n",
    "axs[1,2].scatter(features_scaled_train[:,5], target_accuracy_train,\n",
    "                label=f\"rho={stats.spearmanr(features_scaled_train[:,4], target_accuracy_train)[0]}\")\n",
    "axs[1,2].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "05ff4f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 48.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   3.,   0.,   0.,   1.,   0.,   1.,   0.,   0.,\n",
       "         28.,   0.,   0.,   0.,   1.,   0.,   0.,   7.,   0.,   4.,   0.,\n",
       "          3.,   3.,   0.,   1.,   0.,   0., 120.,   0.,   1.,   0.,   1.,\n",
       "          5.,   0.,  11.,   4.,   0.,  25.,   3.,  13.,  10.,   5.,   7.,\n",
       "        116.,   1.,   9.,  30.,   9.,  23.,  14.,  12.,   6., 102.,  23.,\n",
       "         44.,  34.,  11., 107.,  35.,  26.,  72.,  27.,  74.,  25.,  46.,\n",
       "         45.,   8.,  53.,  22.,  21.,  13.,  18.,   3.,  10.,   1.,   0.,\n",
       "        608.]),\n",
       " array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
       "        0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
       "        0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
       "        0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
       "        0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
       "        0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
       "        0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
       "        0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
       "        0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
       "        0.99, 1.  ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(target_accuracy, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b558f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
